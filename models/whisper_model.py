"""
–õ–æ–∫–∞–ª—å–Ω–∞ –º–æ–¥–µ–ª—å faster-whisper –¥–ª—è —à–≤–∏–¥–∫–æ—ó —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∞—É–¥—ñ–æ
"""

import os
import logging
import numpy as np
from typing import Dict, Any, Optional, List, Tuple
import torch
import librosa
import soundfile as sf
import time

from .config import (
    MODELS_DIR, logger, SPEED_OPTIMIZED_BEAM_SIZE, SPEED_OPTIMIZED_VAD,
    SUPPORTED_MODELS, QUANTIZED_MODELS, CPU_COMPUTE_TYPE, GPU_COMPUTE_TYPE
)

# –Ü–º–ø–æ—Ä—Ç –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –º–æ–¥–µ–ª–µ–π
try:
    from .model_manager import model_manager
    MODEL_MANAGER_AVAILABLE = True
except ImportError:
    MODEL_MANAGER_AVAILABLE = False
    logger.warning("–ú–µ–Ω–µ–¥–∂–µ—Ä –º–æ–¥–µ–ª–µ–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π")

# –Ü–º–ø–æ—Ä—Ç soxr –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ —Ä–µ—Å–µ–º–ø–ª—ñ–Ω–≥—É
try:
    import soxr
    SOXR_AVAILABLE = True
    logger.info("soxr –¥–æ—Å—Ç—É–ø–Ω–∏–π –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ —Ä–µ—Å–µ–º–ø–ª—ñ–Ω–≥—É")
except ImportError:
    SOXR_AVAILABLE = False
    logger.warning("soxr –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è librosa")

class LocalWhisperModel:
    """–õ–æ–∫–∞–ª—å–Ω–∞ –º–æ–¥–µ–ª—å faster-whisper –¥–ª—è —à–≤–∏–¥–∫–æ—ó —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∞—É–¥—ñ–æ"""
    
    def __init__(self, model_size: str = "small", device: str = "cpu", transcription_service=None):
        self.model_size = model_size
        self.device = device
        self.model = None
        self.transcription_service = transcription_service  # –ü–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –æ—Å–Ω–æ–≤–Ω–∏–π —Å–µ—Ä–≤—ñ—Å –¥–ª—è –∫–µ—à—É–≤–∞–Ω–Ω—è
        
    def load_model(self) -> bool:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î faster-whisper –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä –º–æ–¥–µ–ª–µ–π"""
        try:
            if MODEL_MANAGER_AVAILABLE:
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –º–µ–Ω–µ–¥–∂–µ—Ä –º–æ–¥–µ–ª–µ–π –¥–ª—è lazy loading
                self.model = model_manager.load_model(self.model_size, self.device)
                if self.model:
                    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {self.model_size} –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ —á–µ—Ä–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä")
                    return True
                else:
                    logger.error(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å {self.model_size}")
                    return False
            else:
                # Fallback –Ω–∞ —Å—Ç–∞—Ä–∏–π –º–µ—Ç–æ–¥
                return self._load_model_fallback()
                
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ —á–µ—Ä–µ–∑ –º–µ–Ω–µ–¥–∂–µ—Ä: {e}")
            return self._load_model_fallback()
    
    def _load_model_fallback(self) -> bool:
        """Fallback –º–µ—Ç–æ–¥ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ"""
        try:
            from faster_whisper import WhisperModel
            
            # –û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è CPU-only —Å–µ—Ä–≤–µ—Ä–∞ (8 CPU + 14GB RAM)
            if self.device == "cpu":
                compute_type = CPU_COMPUTE_TYPE  # int8 –¥–ª—è CPU
                cpu_threads = min(8, os.cpu_count() or 8)  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –≤—Å—ñ 8 CPU
                model_name = self.model_size
                logger.info(f"üöÄ CPU-only –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è (fallback): model={model_name} (quantized), compute_type={compute_type}, cpu_threads={cpu_threads}")
            else:
                # –î–ª—è GPU: –∑–∞–≤–∂–¥–∏ float16 (—Ö–æ—á–∞ –≤–∏ –∑–∞–≤–∂–¥–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç–µ CPU)
                compute_type = GPU_COMPUTE_TYPE
                cpu_threads = 2  # –ë—ñ–ª—å—à–µ –ø–æ—Ç–æ–∫—ñ–≤ –¥–ª—è GPU
                model_name = self.model_size
                logger.info(f"üöÄ GPU –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è (fallback): model={model_name}, compute_type={compute_type}")
            
            logger.info(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è faster-whisper –º–æ–¥–µ–ª—ñ {self.model_size} (fallback)...")
            
            try:
                self.model = WhisperModel(
                    model_name,
                    device=self.device, 
                    compute_type=compute_type,
                    cpu_threads=cpu_threads,
                    num_workers=2 if self.device == "cpu" else 1,  # –ó–º–µ–Ω—à–µ–Ω–æ –¥–ª—è –µ–∫–æ–Ω–æ–º—ñ—ó –ø–∞–º'—è—Ç—ñ
                    download_root=str(MODELS_DIR)
                )
            except Exception as e:
                # Fallback: —Å–ø—Ä–æ–±—É—î–º–æ –∑ float16 —è–∫—â–æ int8 –Ω–µ –ø—Ä–∞—Ü—é—î
                if self.device == "cpu" and compute_type == "int8":
                    logger.warning(f"Quantized –º–æ–¥–µ–ª—å (int8) –Ω–µ –ø—Ä–∞—Ü—é—î: {e}")
                    logger.info("Fallback –Ω–∞ float16...")
                    self.model = WhisperModel(
                        self.model_size, 
                        device=self.device, 
                        compute_type="float16",
                        cpu_threads=cpu_threads,
                        num_workers=2 if self.device == "cpu" else 1,
                        download_root=str(MODELS_DIR)
                    )
                else:
                    raise e
            
            logger.info(f"faster-whisper –º–æ–¥–µ–ª—å {self.model_size} –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ —É—Å–ø—ñ—à–Ω–æ (fallback, compute_type: {compute_type})")
            return True
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è faster-whisper (fallback): {e}")
            return False
    
    
    def transcribe(self, audio_path: str, language: str = "uk") -> Dict[str, Any]:
        """–®–≤–∏–¥–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –∑ faster-whisper (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó —à–≤–∏–¥–∫–æ—Å—Ç—ñ)"""
        if self.model is None:
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞")
        
        try:
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∞—É–¥—ñ–æ –Ω–∞–ø—Ä—è–º—É —è–∫ –º–∞—Å–∏–≤ (–±–µ–∑ —Ç–∏–º—á–∞—Å–æ–≤–∏—Ö —Ñ–∞–π–ª—ñ–≤)
            audio, sr = self._load_and_preprocess_audio(audio_path)
            
            logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –∞—É–¥—ñ–æ –º–∞—Å–∏–≤—É (—Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å: {len(audio)/sr:.1f}—Å)")
            logger.info(f"üîç VAD —Ñ—ñ–ª—å—Ç—Ä: {'–£–í–Ü–ú–ö–ù–ï–ù–û' if SPEED_OPTIMIZED_VAD else '–í–ò–ú–ö–ù–ï–ù–û'}")
            
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó —à–≤–∏–¥–∫–æ—Å—Ç—ñ
            segments, info = self.model.transcribe(
                audio,  # –ü–µ—Ä–µ–¥–∞—î–º–æ –º–∞—Å–∏–≤ –Ω–∞–ø—Ä—è–º—É
                language=language,
                beam_size=1,  # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
                word_timestamps=False,  # –í–∏–º–∫–Ω–µ–Ω–æ –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
                vad_filter=SPEED_OPTIMIZED_VAD,  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—É –∑ –∫–æ–Ω—Ñ—ñ–≥—É
                vad_parameters=dict(
                    min_silence_duration_ms=500,  # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å —Ç–∏—à—ñ
                    speech_pad_ms=200,  # –ë—É—Ñ–µ—Ä –Ω–∞–≤–∫–æ–ª–æ –º–æ–≤–ª–µ–Ω–Ω—è
                ),
                temperature=0.0,  # –î–µ—Ç–µ—Ä–º—ñ–Ω—ñ—Å—Ç–∏—á–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                best_of=1,  # –¢—ñ–ª—å–∫–∏ –æ–¥–∏–Ω –≤–∞—Ä—ñ–∞–Ω—Ç
                condition_on_previous_text=False,  # –í–∏–º–∫–Ω–µ–Ω–æ –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
                initial_prompt=None,  # –ë–µ–∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ–≥–æ —Ç–µ–∫—Å—Ç—É
                # suppress_tokens –∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º (–Ω–µ –≤–∫–∞–∑—É—î–º–æ —è–≤–Ω–æ)
            )
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É —Ñ–æ—Ä–º–∞—Ç, —Å—É–º—ñ—Å–Ω–∏–π –∑ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–º API
            segments_list = []
            full_text = ""
            
            for segment in segments:
                segment_dict = {
                    "start": segment.start,
                    "end": segment.end,
                    "text": segment.text.strip()
                }
                segments_list.append(segment_dict)
                full_text += segment.text + " "
            
            result = {
                "text": full_text.strip(),
                "segments": segments_list,
                "duration": info.duration,
                "language": language
            }
            
            return result
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó: {e}")
            raise
    
    def _load_and_preprocess_audio(self, audio_path: str) -> Tuple[np.ndarray, int]:
        """–®–≤–∏–¥–∫–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –æ–±—Ä–æ–±–∫–∞ –∞—É–¥—ñ–æ –∑ soxr (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∏–π)"""
        try:
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∞—É–¥—ñ–æ —Ñ–∞–π–ª
            if SOXR_AVAILABLE:
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ soxr –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ —Ä–µ—Å–µ–º–ø–ª—ñ–Ω–≥—É
                # soxr.resample(audio, orig_sr, target_sr) - –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π API
                audio, orig_sr = librosa.load(audio_path, sr=None, mono=True)  # –°–ø–æ—á–∞—Ç–∫—É –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ
                if orig_sr != 16000:
                    audio = soxr.resample(audio, orig_sr, 16000)  # –ü–æ—Ç—ñ–º —Ä–µ—Å–µ–º–ø–ª—ñ–º–æ —á–µ—Ä–µ–∑ soxr
                    logger.debug(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —á–µ—Ä–µ–∑ soxr: {orig_sr}Hz -> 16000Hz")
                else:
                    logger.debug(f"–ê—É–¥—ñ–æ –≤–∂–µ 16kHz, —Ä–µ—Å–µ–º–ø–ª—ñ–Ω–≥ –Ω–µ –ø–æ—Ç—Ä—ñ–±–µ–Ω")
            else:
                # Fallback –Ω–∞ librosa
                audio, sr = librosa.load(audio_path, sr=16000, mono=True)
                logger.debug(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —á–µ—Ä–µ–∑ librosa: {sr}Hz -> 16000Hz")
            
            return audio, 16000
            
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ: {e}, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è fallback")
            # Fallback –Ω–∞ librosa
            audio, sr = librosa.load(audio_path, sr=16000, mono=True)
            return audio, 16000
    
    def _convert_to_optimal_format(self, audio_path: str) -> tuple[np.ndarray, int]:
        """–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–∏—Ö –∞—É–¥—ñ–æ 8kHz (—Ç–µ–ª–µ—Ñ–æ–Ω–Ω–∞ —è–∫—ñ—Å—Ç—å) –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–æ—é –æ–±—Ä–æ–±–∫–æ—é –ø–æ—á–∞—Ç–∫—É
        –ü–æ–≤–µ—Ä—Ç–∞—î numpy –º–∞—Å–∏–≤ –∑–∞–º—ñ—Å—Ç—å —Ñ–∞–π–ª—É –¥–ª—è —à–≤–∏–¥—à–æ—ó –æ–±—Ä–æ–±–∫–∏"""
        try:
            logger.info(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è —Ñ–∞–π–ª—É –≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç: {audio_path}")
            
            # –°–ø—Ä–æ–±—É—î–º–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ GPU –¥–ª—è —à–≤–∏–¥—à–æ—ó –æ–±—Ä–æ–±–∫–∏
            if torch.cuda.is_available():
                try:
                    audio, sr = self._convert_audio_gpu(audio_path)
                    logger.info("–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ GPU –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó")
                except Exception as e:
                    logger.warning(f"GPU –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –Ω–µ –≤–¥–∞–ª–∞—Å—è: {e}, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è CPU")
                    audio, sr = librosa.load(audio_path, sr=None, mono=True)
            else:
                # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∞—É–¥—ñ–æ —Ñ–∞–π–ª (–∑–∞–≤–∂–¥–∏ –º–æ–Ω–æ) –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                audio, sr = librosa.load(audio_path, sr=None, mono=True, offset=0.0)
            
            # –î–æ–¥–∞—î–º–æ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –±—É—Ñ–µ—Ä —Ç–∏—à—ñ –Ω–∞ –ø–æ—á–∞—Ç–æ–∫ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –≤–∏—è–≤–ª–µ–Ω–Ω—è –ø–µ—Ä—à–∏—Ö —Å–ª—ñ–≤
            silence_buffer = np.zeros(int(0.05 * sr))  # 0.05 —Å–µ–∫—É–Ω–¥–∏ —Ç–∏—à—ñ (–∑–º–µ–Ω—à–µ–Ω–æ)
            audio = np.concatenate([silence_buffer, audio])
            
            # –ó–∞–≤–∂–¥–∏ –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ 16kHz –¥–ª—è Whisper
            if sr != 16000:
                logger.info(f"–†–µ—Å–µ–º–ø–ª—ñ–Ω–≥ –∑ {sr}Hz –¥–æ 16000Hz")
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∫—Ä–∞—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–µ—Å–µ–º–ø–ª—ñ–Ω–≥—É –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —è–∫–æ—Å—Ç—ñ
                audio = librosa.resample(audio, orig_sr=sr, target_sr=16000, res_type='kaiser_best')
                sr = 16000
            
            logger.info(f"‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(audio)} –∑—Ä–∞–∑–∫—ñ–≤, {sr}Hz")
            return audio, sr
            
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó –≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç: {e}")
            # Fallback: –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π —Ñ–∞–π–ª
            audio, sr = librosa.load(audio_path, sr=16000, mono=True)
            return audio, sr
    
    def _convert_audio_gpu(self, audio_path: str) -> Tuple[np.ndarray, int]:
        """GPU-–ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∞—É–¥—ñ–æ"""
        try:
            import torchaudio
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∞—É–¥—ñ–æ –Ω–∞ GPU
            waveform, sample_rate = torchaudio.load(audio_path)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ –º–æ–Ω–æ —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
            if waveform.shape[0] > 1:
                waveform = torch.mean(waveform, dim=0, keepdim=True)
            
            # –†–µ—Å–µ–º–ø–ª—ñ–Ω–≥ –Ω–∞ GPU —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
            if sample_rate != 16000:
                resampler = torchaudio.transforms.Resample(sample_rate, 16000)
                waveform = resampler(waveform)
                sample_rate = 16000
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –Ω–∞–∑–∞–¥ –≤ numpy
            audio = waveform.squeeze().cpu().numpy()
            
            return audio, sample_rate
            
        except ImportError:
            logger.warning("torchaudio –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–π, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è CPU")
            raise
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ GPU –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó: {e}")
            raise
    
    def _post_process_transcription(self, result: Dict[str, Any], language: str) -> Dict[str, Any]:
        """–ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –ø–æ—Å—Ç-–æ–±—Ä–æ–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É"""
        try:
            # –¢—ñ–ª—å–∫–∏ –±–∞–∑–æ–≤–µ –æ—á–∏—â–µ–Ω–Ω—è —Ç–µ–∫—Å—Ç—É
            if "text" in result:
                result["text"] = result["text"].strip()
            
            # –û—á–∏—â–µ–Ω–Ω—è —Å–µ–≥–º–µ–Ω—Ç—ñ–≤
            if "segments" in result:
                for segment in result["segments"]:
                    if "text" in segment:
                        segment["text"] = segment["text"].strip()
            
            return result
            
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –ø–æ—Å—Ç-–æ–±—Ä–æ–±–∫–∏: {e}")
            return result
    
    
    
    def _load_audio_cached(self, audio_path: str) -> Tuple[np.ndarray, int]:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –∞—É–¥—ñ–æ –∑ –¥–∏—Å–∫—É (–∫–µ—à—É–≤–∞–Ω–Ω—è –≤–∏–º–∫–Ω–µ–Ω–æ)"""
        # –ö–µ—à—É–≤–∞–Ω–Ω—è –≤–∏–º–∫–Ω–µ–Ω–æ - –∑–∞–≤–∂–¥–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑ –¥–∏—Å–∫—É
        logger.debug(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ –∑ –¥–∏—Å–∫—É: {audio_path}")
        audio, sr = librosa.load(audio_path, sr=16000, mono=True)
        return audio, sr
    
    


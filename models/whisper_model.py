"""
–õ–æ–∫–∞–ª—å–Ω–∞ –º–æ–¥–µ–ª—å faster-whisper –¥–ª—è —à–≤–∏–¥–∫–æ—ó —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∞—É–¥—ñ–æ
"""

import os
import logging
import numpy as np
from typing import Dict, Any, Optional, List, Tuple
import torch
import librosa
import soundfile as sf
import asyncio
from concurrent.futures import ProcessPoolExecutor
import time
import multiprocessing as mp

from .config import (
    MODELS_DIR, logger, SPEED_OPTIMIZED_BEAM_SIZE, SPEED_OPTIMIZED_VAD,
    SPEED_OPTIMIZED_CHUNK_SIZES, SUPPORTED_MODELS
)

# –Ü–º–ø–æ—Ä—Ç soxr –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ —Ä–µ—Å–µ–º–ø–ª—ñ–Ω–≥—É
try:
    import soxr
    SOXR_AVAILABLE = True
    logger.info("soxr –¥–æ—Å—Ç—É–ø–Ω–∏–π –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ —Ä–µ—Å–µ–º–ø–ª—ñ–Ω–≥—É")
except ImportError:
    SOXR_AVAILABLE = False
    logger.warning("soxr –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è librosa")

class LocalWhisperModel:
    """–õ–æ–∫–∞–ª—å–Ω–∞ –º–æ–¥–µ–ª—å faster-whisper –¥–ª—è —à–≤–∏–¥–∫–æ—ó —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∞—É–¥—ñ–æ"""
    
    def __init__(self, model_size: str = "small", device: str = "cpu", transcription_service=None):
        self.model_size = model_size
        self.device = device
        self.model = None
        self.transcription_service = transcription_service  # –ü–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –æ—Å–Ω–æ–≤–Ω–∏–π —Å–µ—Ä–≤—ñ—Å –¥–ª—è –∫–µ—à—É–≤–∞–Ω–Ω—è
        
    def load_model(self) -> bool:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î faster-whisper –º–æ–¥–µ–ª—å –≤ –ª–æ–∫–∞–ª—å–Ω—É –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é –ø—Ä–æ–µ–∫—Ç—É"""
        try:
            from faster_whisper import WhisperModel
            
            # –û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó —à–≤–∏–¥–∫–æ—Å—Ç—ñ
            if self.device == "cpu":
                # –î–ª—è CPU: —Å–ø—Ä–æ–±—É—î–º–æ int8_float16, fallback –Ω–∞ int8
                try:
                    import psutil
                    memory_gb = psutil.virtual_memory().total / (1024**3)
                    if memory_gb >= 8:
                        compute_type = "int8_float16"  # –®–≤–∏–¥—à–µ –Ω—ñ–∂ int8
                        logger.info("–°–ø—Ä–æ–±–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ int8_float16 –¥–ª—è CPU (—à–≤–∏–¥—à–µ)")
                    else:
                        compute_type = "int8"  # –ï–∫–æ–Ω–æ–º–Ω—ñ—à–µ –ø–æ –ø–∞–º'—è—Ç—ñ
                        logger.info("–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è int8 –¥–ª—è CPU (–µ–∫–æ–Ω–æ–º–Ω–æ)")
                except:
                    compute_type = "int8"
            else:
                # –î–ª—è GPU: –∑–∞–≤–∂–¥–∏ float16
                compute_type = "float16"
                logger.info("–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è float16 –¥–ª—è GPU")
            
            # –®–ª—è—Ö –¥–æ –º–æ–¥–µ–ª—ñ –≤ –ª–æ–∫–∞–ª—å–Ω—ñ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó –ø—Ä–æ–µ–∫—Ç—É
            model_path = MODELS_DIR / f"faster-whisper-{self.model_size}"
            
            logger.info(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è faster-whisper –º–æ–¥–µ–ª—ñ {self.model_size} –≤ {model_path}...")
            
            try:
                self.model = WhisperModel(
                    self.model_size, 
                    device=self.device, 
                    compute_type=compute_type,
                    download_root=str(MODELS_DIR)  # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤ –ª–æ–∫–∞–ª—å–Ω—É –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é
                )
            except Exception as e:
                if "int8_float16" in str(e) and compute_type == "int8_float16":
                    # Fallback –Ω–∞ int8 —è–∫—â–æ int8_float16 –Ω–µ –ø—ñ–¥—Ç—Ä–∏–º—É—î—Ç—å—Å—è
                    logger.warning(f"int8_float16 –Ω–µ –ø—ñ–¥—Ç—Ä–∏–º—É—î—Ç—å—Å—è: {e}")
                    logger.info("Fallback –Ω–∞ int8...")
                    compute_type = "int8"
                    self.model = WhisperModel(
                        self.model_size, 
                        device=self.device, 
                        compute_type=compute_type,
                        download_root=str(MODELS_DIR)
                    )
                else:
                    raise e
            
            logger.info(f"faster-whisper –º–æ–¥–µ–ª—å {self.model_size} –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ —É—Å–ø—ñ—à–Ω–æ –≤ {MODELS_DIR} (compute_type: {compute_type})")
            return True
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è faster-whisper: {e}")
            return False
    
    def _get_optimal_model_size(self) -> str:
        """–í–∏–∑–Ω–∞—á–∞—î –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö —Ä–µ—Å—É—Ä—Å—ñ–≤"""
        try:
            import psutil
            
            # –û—Ç—Ä–∏–º—É—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Å–∏—Å—Ç–µ–º—É
            memory_gb = psutil.virtual_memory().total / (1024**3)
            cpu_count = psutil.cpu_count()
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ä–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ä–µ—Å—É—Ä—Å—ñ–≤ (—Ç—ñ–ª—å–∫–∏ small —Ç–∞ medium)
            if memory_gb >= 4 and cpu_count >= 2:
                return "medium"
            else:
                return "small"
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ä–µ—Å—É—Ä—Å—ñ–≤: {e}, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è small –º–æ–¥–µ–ª—å")
            return "small"
    
    def transcribe(self, audio_path: str, language: str = "uk") -> Dict[str, Any]:
        """–®–≤–∏–¥–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –∑ faster-whisper (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó —à–≤–∏–¥–∫–æ—Å—Ç—ñ)"""
        if self.model is None:
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞")
        
        try:
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∞—É–¥—ñ–æ –Ω–∞–ø—Ä—è–º—É —è–∫ –º–∞—Å–∏–≤ (–±–µ–∑ —Ç–∏–º—á–∞—Å–æ–≤–∏—Ö —Ñ–∞–π–ª—ñ–≤)
            audio, sr = self._load_and_preprocess_audio(audio_path)
            
            logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –∞—É–¥—ñ–æ –º–∞—Å–∏–≤—É (—Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å: {len(audio)/sr:.1f}—Å)")
            logger.info(f"üîç VAD —Ñ—ñ–ª—å—Ç—Ä: {'–£–í–Ü–ú–ö–ù–ï–ù–û' if SPEED_OPTIMIZED_VAD else '–í–ò–ú–ö–ù–ï–ù–û'}")
            
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó —à–≤–∏–¥–∫–æ—Å—Ç—ñ
            segments, info = self.model.transcribe(
                audio,  # –ü–µ—Ä–µ–¥–∞—î–º–æ –º–∞—Å–∏–≤ –Ω–∞–ø—Ä—è–º—É
                language=language,
                beam_size=SPEED_OPTIMIZED_BEAM_SIZE,  # –ó–∞–≤–∂–¥–∏ 1
                word_timestamps=True,
                vad_filter=SPEED_OPTIMIZED_VAD,  # –¢–µ–ø–µ—Ä True –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –≤–∏—è–≤–ª–µ–Ω–Ω—è
                vad_parameters=dict(
                    min_silence_duration_ms=300,  # –ó–º–µ–Ω—à–µ–Ω–æ –∑ 500 –¥–æ 300 –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –≤–∏—è–≤–ª–µ–Ω–Ω—è
                    speech_pad_ms=100,  # –î–æ–¥–∞–Ω–æ –±—É—Ñ–µ—Ä –Ω–∞–≤–∫–æ–ª–æ –º–æ–≤–ª–µ–Ω–Ω—è
                ) if SPEED_OPTIMIZED_VAD else None,
                temperature=0.0,  # –î–µ—Ç–µ—Ä–º—ñ–Ω—ñ—Å—Ç–∏—á–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                best_of=1,  # –¢—ñ–ª—å–∫–∏ –æ–¥–∏–Ω –≤–∞—Ä—ñ–∞–Ω—Ç
            )
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É —Ñ–æ—Ä–º–∞—Ç, —Å—É–º—ñ—Å–Ω–∏–π –∑ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–º API
            segments_list = []
            full_text = ""
            
            for segment in segments:
                segment_dict = {
                    "start": segment.start,
                    "end": segment.end,
                    "text": segment.text.strip()
                }
                segments_list.append(segment_dict)
                full_text += segment.text + " "
            
            result = {
                "text": full_text.strip(),
                "segments": segments_list,
                "duration": info.duration,
                "language": language
            }
            
            return result
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó: {e}")
            raise
    
    def _load_and_preprocess_audio(self, audio_path: str) -> Tuple[np.ndarray, int]:
        """–®–≤–∏–¥–∫–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –æ–±—Ä–æ–±–∫–∞ –∞—É–¥—ñ–æ –∑ soxr (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∏–π)"""
        try:
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∞—É–¥—ñ–æ —Ñ–∞–π–ª
            if SOXR_AVAILABLE:
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ soxr –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ —Ä–µ—Å–µ–º–ø–ª—ñ–Ω–≥—É
                # soxr.resample(audio, orig_sr, target_sr) - –ø—Ä–∞–≤–∏–ª—å–Ω–∏–π API
                audio, orig_sr = librosa.load(audio_path, sr=None, mono=True)  # –°–ø–æ—á–∞—Ç–∫—É –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ
                if orig_sr != 16000:
                    audio = soxr.resample(audio, orig_sr, 16000)  # –ü–æ—Ç—ñ–º —Ä–µ—Å–µ–º–ø–ª—ñ–º–æ —á–µ—Ä–µ–∑ soxr
                    logger.debug(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —á–µ—Ä–µ–∑ soxr: {orig_sr}Hz -> 16000Hz")
                else:
                    logger.debug(f"–ê—É–¥—ñ–æ –≤–∂–µ 16kHz, —Ä–µ—Å–µ–º–ø–ª—ñ–Ω–≥ –Ω–µ –ø–æ—Ç—Ä—ñ–±–µ–Ω")
            else:
                # Fallback –Ω–∞ librosa
                audio, sr = librosa.load(audio_path, sr=16000, mono=True)
                logger.debug(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —á–µ—Ä–µ–∑ librosa: {sr}Hz -> 16000Hz")
            
            return audio, 16000
            
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ: {e}, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è fallback")
            # Fallback –Ω–∞ librosa
            audio, sr = librosa.load(audio_path, sr=16000, mono=True)
            return audio, 16000
    
    def _convert_to_optimal_format(self, audio_path: str) -> str:
        """–û–ø—Ç–∏–º–∞–ª—å–Ω–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–∏—Ö –∞—É–¥—ñ–æ 8kHz (—Ç–µ–ª–µ—Ñ–æ–Ω–Ω–∞ —è–∫—ñ—Å—Ç—å) –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–æ—é –æ–±—Ä–æ–±–∫–æ—é –ø–æ—á–∞—Ç–∫—É"""
        try:
            logger.info(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è —Ñ–∞–π–ª—É –≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç: {audio_path}")
            
            # –°–ø—Ä–æ–±—É—î–º–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ GPU –¥–ª—è —à–≤–∏–¥—à–æ—ó –æ–±—Ä–æ–±–∫–∏
            if torch.cuda.is_available():
                try:
                    audio, sr = self._convert_audio_gpu(audio_path)
                    logger.info("–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ GPU –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó")
                except Exception as e:
                    logger.warning(f"GPU –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –Ω–µ –≤–¥–∞–ª–∞—Å—è: {e}, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è CPU")
                    audio, sr = librosa.load(audio_path, sr=None, mono=True)
            else:
                # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∞—É–¥—ñ–æ —Ñ–∞–π–ª (–∑–∞–≤–∂–¥–∏ –º–æ–Ω–æ) –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                audio, sr = librosa.load(audio_path, sr=None, mono=True, offset=0.0)
            
            # –î–æ–¥–∞—î–º–æ –Ω–µ–≤–µ–ª–∏–∫–∏–π –±—É—Ñ–µ—Ä —Ç–∏—à—ñ –Ω–∞ –ø–æ—á–∞—Ç–æ–∫ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –≤–∏—è–≤–ª–µ–Ω–Ω—è –ø–µ—Ä—à–∏—Ö —Å–ª—ñ–≤
            silence_buffer = np.zeros(int(0.1 * sr))  # 0.1 —Å–µ–∫—É–Ω–¥–∏ —Ç–∏—à—ñ
            audio = np.concatenate([silence_buffer, audio])
            
            # –ó–∞–≤–∂–¥–∏ –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ 16kHz –¥–ª—è Whisper
            if sr != 16000:
                logger.info(f"–†–µ—Å–µ–º–ø–ª—ñ–Ω–≥ –∑ {sr}Hz –¥–æ 16000Hz")
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∫—Ä–∞—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–µ—Å–µ–º–ø–ª—ñ–Ω–≥—É –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —è–∫–æ—Å—Ç—ñ
                audio = librosa.resample(audio, orig_sr=sr, target_sr=16000, res_type='kaiser_best')
                sr = 16000
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤–∏–π WAV —Ñ–∞–π–ª (–Ω–∞–π–∫—Ä–∞—â–∏–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è Whisper)
            temp_wav = audio_path.rsplit('.', 1)[0] + '_temp.wav'
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —è–∫ WAV PCM_16 mono –∑ –ø–æ–∫—Ä–∞—â–µ–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            sf.write(temp_wav, audio, 16000, format='WAV', subtype='PCM_16')
            
            logger.info(f"–§–∞–π–ª –∫–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–æ –≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç: {temp_wav} (–¥–æ–¥–∞–Ω–æ –±—É—Ñ–µ—Ä —Ç–∏—à—ñ –Ω–∞ –ø–æ—á–∞—Ç–æ–∫)")
            return temp_wav
            
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó –≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç: {e}")
            return audio_path  # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π —Ñ–∞–π–ª
    
    def _convert_audio_gpu(self, audio_path: str) -> Tuple[np.ndarray, int]:
        """GPU-–ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∞—É–¥—ñ–æ"""
        try:
            import torchaudio
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∞—É–¥—ñ–æ –Ω–∞ GPU
            waveform, sample_rate = torchaudio.load(audio_path)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ –º–æ–Ω–æ —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
            if waveform.shape[0] > 1:
                waveform = torch.mean(waveform, dim=0, keepdim=True)
            
            # –†–µ—Å–µ–º–ø–ª—ñ–Ω–≥ –Ω–∞ GPU —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ
            if sample_rate != 16000:
                resampler = torchaudio.transforms.Resample(sample_rate, 16000)
                waveform = resampler(waveform)
                sample_rate = 16000
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –Ω–∞–∑–∞–¥ –≤ numpy
            audio = waveform.squeeze().cpu().numpy()
            
            return audio, sample_rate
            
        except ImportError:
            logger.warning("torchaudio –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–π, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è CPU")
            raise
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ GPU –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó: {e}")
            raise
    
    def _post_process_transcription(self, result: Dict[str, Any], language: str) -> Dict[str, Any]:
        """–ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –ø–æ—Å—Ç-–æ–±—Ä–æ–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É"""
        try:
            # –¢—ñ–ª—å–∫–∏ –±–∞–∑–æ–≤–µ –æ—á–∏—â–µ–Ω–Ω—è —Ç–µ–∫—Å—Ç—É
            if "text" in result:
                result["text"] = result["text"].strip()
            
            # –û—á–∏—â–µ–Ω–Ω—è —Å–µ–≥–º–µ–Ω—Ç—ñ–≤
            if "segments" in result:
                for segment in result["segments"]:
                    if "text" in segment:
                        segment["text"] = segment["text"].strip()
            
            return result
            
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –ø–æ—Å—Ç-–æ–±—Ä–æ–±–∫–∏: {e}")
            return result
    
    def _get_optimal_chunk_size(self, duration: float) -> int:
        """–í–∏–∑–Ω–∞—á–∞—î –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–º—ñ—Ä —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó —à–≤–∏–¥–∫–æ—Å—Ç—ñ"""
        logger.info(f"üîç –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä—É —á–∞–Ω–∫—É –¥–ª—è —Ñ–∞–π–ª—É —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—é {duration:.1f}s")
        
        # –î–ª—è —Ñ–∞–π–ª—ñ–≤ –∫–æ—Ä–æ—Ç—à–∏—Ö –∑–∞ 2 —Ö–≤–∏–ª–∏–Ω–∏ - –Ω–µ —Ä–æ–∑–±–∏–≤–∞—î–º–æ –Ω–∞ —á–∞–Ω–∫–∏
        if duration < 120:  # < 2 —Ö–≤
            chunk_size = int(duration) + 1
            logger.info(f"üîç –§–∞–π–ª < 2 —Ö–≤: chunk_size = {chunk_size}s (–Ω–µ —Ä–æ–∑–±–∏–≤–∞—î–º–æ)")
            return chunk_size
        elif duration < 1800:  # < 30 —Ö–≤
            chunk_size = SPEED_OPTIMIZED_CHUNK_SIZES['medium']
            logger.info(f"üîç –§–∞–π–ª 2-30 —Ö–≤: chunk_size = {chunk_size}s (medium)")
            return chunk_size
        else:  # > 30 —Ö–≤
            chunk_size = SPEED_OPTIMIZED_CHUNK_SIZES['long']
            logger.info(f"üîç –§–∞–π–ª > 30 —Ö–≤: chunk_size = {chunk_size}s (long)")
            return chunk_size
    
    def _split_audio_into_chunks(self, audio_path: str, chunk_duration: int = None) -> List[Tuple[np.ndarray, int, float, float]]:
        """–†–æ–∑–±–∏–≤–∞—î –∞—É–¥—ñ–æ —Ñ–∞–π–ª –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∏ —è–∫ –º–∞—Å–∏–≤–∏ –∑ —á–∞—Å–æ–≤–∏–º–∏ –º—ñ—Ç–∫–∞–º–∏"""
        try:
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∞—É–¥—ñ–æ —à–≤–∏–¥–∫–∏–º –º–µ—Ç–æ–¥–æ–º
            audio, sr = self._load_and_preprocess_audio(audio_path)
            duration = len(audio) / sr
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π —Ä–æ–∑–º—ñ—Ä —Å–µ–≥–º–µ–Ω—Ç—ñ–≤
            if chunk_duration is None:
                chunk_duration = self._get_optimal_chunk_size(duration)
            
            logger.info(f"–†–æ–∑–±–∏—Ç—Ç—è –∞—É–¥—ñ–æ –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∏ –ø–æ {chunk_duration} —Å–µ–∫—É–Ω–¥ (—Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å: {duration:.1f}—Å)...")
            logger.info(f"üîç –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: duration={duration:.1f}s, chunk_duration={chunk_duration}s")
            
            # –Ø–∫—â–æ —Ñ–∞–π–ª –∫–æ—Ä–æ—Ç—à–∏–π –∑–∞ chunk_duration, –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ —è–∫ —î
            if duration <= chunk_duration:
                logger.info(f"‚úÖ –§–∞–π–ª –∫–æ—Ä–æ—Ç—à–∏–π –∑–∞ —Ä–æ–∑–º—ñ—Ä —á–∞–Ω–∫—É ({duration:.1f}—Å <= {chunk_duration}—Å), –æ–±—Ä–æ–±–ª—è—î–º–æ —è–∫ —Ü—ñ–ª–∏–π")
                logger.info(f"‚úÖ –¶–µ –æ–∑–Ω–∞—á–∞—î, —â–æ —Ñ–∞–π–ª –ù–ï –±—É–¥–µ —Ä–æ–∑–±–∏—Ç–æ –Ω–∞ —á–∞–Ω–∫–∏ - —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –ø–æ—á–Ω–µ—Ç—å—Å—è –∑ 0 —Å–µ–∫—É–Ω–¥–∏")
                return [(audio, sr, 0.0, duration)]
            
            # –†–æ–∑–±–∏–≤–∞—î–º–æ –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∏ —è–∫ –º–∞—Å–∏–≤–∏
            chunk_arrays = []
            chunk_samples = chunk_duration * sr
            
            logger.info(f"–†–æ–∑–±–∏—Ç—Ç—è –Ω–∞ —á–∞–Ω–∫–∏: chunk_samples={chunk_samples}, total_samples={len(audio)}")
            
            for i in range(0, len(audio), chunk_samples):
                chunk_audio = audio[i:i + chunk_samples]
                chunk_start_time = i / sr
                chunk_end_time = (i + len(chunk_audio)) / sr
                
                # –î–µ—Ç–∞–ª—å–Ω–∞ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–ª—è –ø–µ—Ä—à–æ–≥–æ —á–∞–Ω–∫—É
                if len(chunk_arrays) == 0:
                    logger.info(f"üîç –ü–ï–†–®–ò–ô –ß–ê–ù–ö: {chunk_start_time:.1f}s - {chunk_end_time:.1f}s ({len(chunk_audio)} –∑—Ä–∞–∑–∫—ñ–≤)")
                    logger.info(f"üîç –ü–æ—á–∞—Ç–æ–∫ –∞—É–¥—ñ–æ: {chunk_start_time:.1f}s (–º–∞—î –±—É—Ç–∏ 0.0s!)")
                    if chunk_start_time > 0:
                        logger.warning(f"‚ö†Ô∏è –£–í–ê–ì–ê: –ü–µ—Ä—à–∏–π —á–∞–Ω–∫ –ø–æ—á–∏–Ω–∞—î—Ç—å—Å—è –∑ {chunk_start_time:.1f}s –∑–∞–º—ñ—Å—Ç—å 0.0s!")
                
                logger.debug(f"–ß–∞–Ω–∫ {len(chunk_arrays)}: {chunk_start_time:.1f}s - {chunk_end_time:.1f}s ({len(chunk_audio)} –∑—Ä–∞–∑–∫—ñ–≤)")
                chunk_arrays.append((chunk_audio, sr, chunk_start_time, chunk_end_time))
            
            logger.info(f"üöÄ –ê—É–¥—ñ–æ —Ä–æ–∑–±–∏—Ç–æ –Ω–∞ {len(chunk_arrays)} —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –ø–æ {chunk_duration}—Å –¥–ª—è —à–≤–∏–¥–∫–æ—ó –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏")
            logger.info(f"‚ö° –¶–µ –∑–Ω–∞—á–Ω–æ –ø—Ä–∏—Å–∫–æ—Ä–∏—Ç—å –æ–±—Ä–æ–±–∫—É —Ñ–∞–π–ª—É!")
            return chunk_arrays
            
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ —Ä–æ–∑–±–∏—Ç—Ç—è –∞—É–¥—ñ–æ: {e}")
            # Fallback: –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤–µ—Å—å —Ñ–∞–π–ª
            audio, sr = self._load_and_preprocess_audio(audio_path)
            return [(audio, sr, 0.0, len(audio) / sr)]
    
    def _load_audio_cached(self, audio_path: str) -> Tuple[np.ndarray, int]:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –∞—É–¥—ñ–æ –∑ –¥–∏—Å–∫—É (–∫–µ—à—É–≤–∞–Ω–Ω—è –≤–∏–º–∫–Ω–µ–Ω–æ)"""
        # –ö–µ—à—É–≤–∞–Ω–Ω—è –≤–∏–º–∫–Ω–µ–Ω–æ - –∑–∞–≤–∂–¥–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑ –¥–∏—Å–∫—É
        logger.debug(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ –∑ –¥–∏—Å–∫—É: {audio_path}")
        audio, sr = librosa.load(audio_path, sr=16000, mono=True)
        return audio, sr
    
    def _transcribe_chunk(self, chunk_audio: np.ndarray, sr: int, language: str) -> Dict[str, Any]:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É—î –æ–¥–∏–Ω —Å–µ–≥–º–µ–Ω—Ç –∞—É–¥—ñ–æ (–º–∞—Å–∏–≤) –∑ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
        try:
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó —à–≤–∏–¥–∫–æ—Å—Ç—ñ
            segments, info = self.model.transcribe(
                chunk_audio,  # –ü–µ—Ä–µ–¥–∞—î–º–æ –º–∞—Å–∏–≤ –Ω–∞–ø—Ä—è–º—É
                language=language,
                beam_size=SPEED_OPTIMIZED_BEAM_SIZE,  # –ó–∞–≤–∂–¥–∏ 1
                word_timestamps=True,
                vad_filter=SPEED_OPTIMIZED_VAD,  # –ó–∞–≤–∂–¥–∏ False
                temperature=0.0,  # –î–µ—Ç–µ—Ä–º—ñ–Ω—ñ—Å—Ç–∏—á–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                best_of=1,  # –¢—ñ–ª—å–∫–∏ –æ–¥–∏–Ω –≤–∞—Ä—ñ–∞–Ω—Ç
            )
            
            segments_list = []
            full_text = ""
            
            for segment in segments:
                segment_dict = {
                    "start": segment.start,
                    "end": segment.end,
                    "text": segment.text.strip()
                }
                segments_list.append(segment_dict)
                full_text += segment.text + " "
            
            return {
                "text": full_text.strip(),
                "segments": segments_list,
                "duration": info.duration,
                "language": language
            }
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó —Å–µ–≥–º–µ–Ω—Ç—É: {e}")
            return {
                "text": "",
                "segments": [],
                "duration": 0,
                "language": language
            }
    
    async def transcribe_parallel(self, audio_path: str, language: str = "uk", chunk_duration: int = None, force_no_chunks: bool = False) -> Dict[str, Any]:
        """–ü–∞—Ä–∞–ª–µ–ª—å–Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –∑ ProcessPoolExecutor –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó —à–≤–∏–¥–∫–æ—Å—Ç—ñ"""
        if self.model is None:
            raise RuntimeError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞")
        
        try:
            # –Ø–∫—â–æ –≤–∏–º–∫–Ω–µ–Ω–æ —á–∞–Ω–∫–∏, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∑–≤–∏—á–∞–π–Ω—É —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—é
            if force_no_chunks:
                logger.info("üö´ –ß–∞–Ω–∫–∏ –≤–∏–º–∫–Ω–µ–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∑–≤–∏—á–∞–π–Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è")
                return self.transcribe(audio_path, language)
            
            # –†–æ–∑–±–∏–≤–∞—î–º–æ –∞—É–¥—ñ–æ –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∏ —è–∫ –º–∞—Å–∏–≤–∏ –∑ —á–∞—Å–æ–≤–∏–º–∏ –º—ñ—Ç–∫–∞–º–∏
            chunk_data = self._split_audio_into_chunks(audio_path, chunk_duration)
            
            # –Ø–∫—â–æ —Ç—ñ–ª—å–∫–∏ –æ–¥–∏–Ω —Å–µ–≥–º–µ–Ω—Ç, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∑–≤–∏—á–∞–π–Ω—É —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—é
            if len(chunk_data) == 1:
                logger.info("‚úÖ –¢—ñ–ª—å–∫–∏ –æ–¥–∏–Ω —á–∞–Ω–∫, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –∑–≤–∏—á–∞–π–Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è")
                return self.transcribe(audio_path, language)
            
            # –î–∏–Ω–∞–º—ñ—á–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –ø—Ä–æ—Ü–µ—Å—ñ–≤
            import os
            max_workers = min(os.cpu_count(), len(chunk_data), 8)  # –û–±–º–µ–∂—É—î–º–æ –¥–ª—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ
            logger.info(f"üöÄ –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è {len(chunk_data)} —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –∑ {max_workers} –ø—Ä–æ—Ü–µ—Å–∞–º–∏...")
            logger.info(f"‚ö° –û—á—ñ–∫—É–≤–∞–Ω–µ –ø—Ä–∏—Å–∫–æ—Ä–µ–Ω–Ω—è: ~{max_workers}x —à–≤–∏–¥—à–µ –Ω—ñ–∂ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–∞ –æ–±—Ä–æ–±–∫–∞")
            
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ ProcessPoolExecutor –¥–ª—è CPU-bound –∑–∞–≤–¥–∞–Ω—å
            with ProcessPoolExecutor(max_workers=max_workers) as executor:
                # –°—Ç–≤–æ—Ä—é—î–º–æ –∑–∞–≤–¥–∞–Ω–Ω—è –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç—É
                loop = asyncio.get_event_loop()
                tasks = [
                    loop.run_in_executor(executor, self._transcribe_chunk_worker, chunk_audio, sr, language)
                    for chunk_audio, sr, start_time, end_time in chunk_data
                ]
                
                # –ß–µ–∫–∞—î–º–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –≤—Å—ñ—Ö –∑–∞–≤–¥–∞–Ω—å
                chunk_results = await asyncio.gather(*tasks)
            
            # –û–±'—î–¥–Ω—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–º–∏ —á–∞—Å–æ–≤–∏–º–∏ –∑–º—ñ—â–µ–Ω–Ω—è–º–∏
            combined_text = ""
            combined_segments = []
            total_duration = 0
            
            logger.info(f"–û–±'—î–¥–Ω–∞–Ω–Ω—è {len(chunk_results)} —á–∞–Ω–∫—ñ–≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó...")
            
            for i, (result, chunk_info) in enumerate(zip(chunk_results, chunk_data)):
                chunk_audio, sr, chunk_start_time, chunk_end_time = chunk_info
                
                # –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –û–±—Ä–æ–±–ª—è—î–º–æ –í–°–Ü —á–∞–Ω–∫–∏, –Ω–∞–≤—ñ—Ç—å —è–∫—â–æ –≤ –Ω–∏—Ö –Ω–µ–º–∞—î —Ç–µ–∫—Å—Ç—É
                if result:  # –¢—ñ–ª—å–∫–∏ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —â–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —ñ—Å–Ω—É—î
                    chunk_text = result.get("text", "").strip()
                    chunk_duration = result.get("duration", 0)
                    
                    logger.debug(f"–ß–∞–Ω–∫ {i}: —Ä–µ–∞–ª—å–Ω–∏–π —á–∞—Å {chunk_start_time:.1f}s-{chunk_end_time:.1f}s, —Ç–µ–∫—Å—Ç='{chunk_text[:50]}...', duration={chunk_duration:.1f}s")
                    
                    # –î–æ–¥–∞—î–º–æ —Ç–µ–∫—Å—Ç (–Ω–∞–≤—ñ—Ç—å —è–∫—â–æ –≤—ñ–Ω –ø–æ—Ä–æ–∂–Ω—ñ–π)
                    if chunk_text:
                        combined_text += chunk_text + " "
                    
                    # –í–ò–ü–†–ê–í–õ–ï–ù–ù–Ø: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ä–µ–∞–ª—å–Ω—É —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å —á–∞–Ω–∫—É –∑–∞–º—ñ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó
                    real_chunk_duration = chunk_end_time - chunk_start_time
                    total_duration += real_chunk_duration
                    
                    # –î–æ–¥–∞—î–º–æ —Å–µ–≥–º–µ–Ω—Ç–∏ –∑ –∫–æ—Ä–µ–∫—Ü—ñ—î—é —á–∞—Å—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ –†–ï–ê–õ–¨–ù–û–ì–û —á–∞—Å—É —á–∞–Ω–∫—É
                    for segment in result.get("segments", []):
                        adjusted_segment = {
                            "start": segment["start"] + chunk_start_time,
                            "end": segment["end"] + chunk_start_time,
                            "text": segment["text"]
                        }
                        combined_segments.append(adjusted_segment)
                        logger.debug(f"–°–µ–≥–º–µ–Ω—Ç: {segment['start']:.1f}s-{segment['end']:.1f}s + {chunk_start_time:.1f}s = {adjusted_segment['start']:.1f}s-{adjusted_segment['end']:.1f}s")
                else:
                    # –Ø–∫—â–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ñ–¥—Å—É—Ç–Ω—ñ–π, –≤—Å–µ –æ–¥–Ω–æ –≤—Ä–∞—Ö–æ–≤—É—î–º–æ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å —á–∞–Ω–∫—É
                    real_chunk_duration = chunk_end_time - chunk_start_time
                    total_duration += real_chunk_duration
                    logger.warning(f"–ß–∞–Ω–∫ {i}: —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ñ–¥—Å—É—Ç–Ω—ñ–π, –∞–ª–µ –≤—Ä–∞—Ö–æ–≤—É—î–º–æ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å {real_chunk_duration:.1f}s")
            
            # –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
            logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–æ–±–∫–∏:")
            logger.info(f"üìä –û–±—Ä–æ–±–ª–µ–Ω–æ —á–∞–Ω–∫—ñ–≤: {len(chunk_results)}/{len(chunk_data)}")
            logger.info(f"üìä –ó–Ω–∞–π–¥–µ–Ω–æ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤: {len(combined_segments)}")
            logger.info(f"üìä –ó–∞–≥–∞–ª—å–Ω–∞ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å: {total_duration:.1f}s")
            logger.info(f"üìä –î–æ–≤–∂–∏–Ω–∞ —Ç–µ–∫—Å—Ç—É: {len(combined_text)} —Å–∏–º–≤–æ–ª—ñ–≤")
            
            if combined_segments:
                logger.info(f"üìä –ü–µ—Ä—à–∏–π —Å–µ–≥–º–µ–Ω—Ç: {combined_segments[0]['start']:.1f}s - {combined_segments[0]['end']:.1f}s")
                logger.info(f"üìä –û—Å—Ç–∞–Ω–Ω—ñ–π —Å–µ–≥–º–µ–Ω—Ç: {combined_segments[-1]['start']:.1f}s - {combined_segments[-1]['end']:.1f}s")
            else:
                logger.warning("‚ö†Ô∏è –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –≤ –æ–±'—î–¥–Ω–∞–Ω–æ–º—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ!")
            
            return {
                "text": combined_text.strip(),
                "segments": combined_segments,
                "duration": total_duration,
                "language": language
            }
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—ó —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó: {e}")
            raise

    @staticmethod
    def _transcribe_chunk_worker(chunk_audio: np.ndarray, sr: int, language: str) -> Dict[str, Any]:
        """Worker —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è ProcessPoolExecutor (—Å—Ç–∞—Ç–∏—á–Ω–∏–π –º–µ—Ç–æ–¥)"""
        try:
            # –Ü–º–ø–æ—Ä—Ç—É—î–º–æ —Ç—É—Ç, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –ø—Ä–æ–±–ª–µ–º –∑ multiprocessing
            from faster_whisper import WhisperModel
            import torch
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø—Ä–∏—Å—Ç—Ä—ñ–π —Ç–∞ compute_type
            device = "cuda" if torch.cuda.is_available() else "cpu"
            if device == "cpu":
                try:
                    import psutil
                    memory_gb = psutil.virtual_memory().total / (1024**3)
                    compute_type = "int8_float16" if memory_gb >= 8 else "int8"
                except:
                    compute_type = "int8"
            else:
                compute_type = "float16"
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å –≤ worker –ø—Ä–æ—Ü–µ—Å—ñ
            model = WhisperModel("small", device=device, compute_type=compute_type)
            
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É—î–º–æ –∑ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            segments, info = model.transcribe(
                chunk_audio,
                language=language,
                beam_size=1,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å
                word_timestamps=True,
                vad_filter=True,  # –£–≤—ñ–º–∫–Ω–µ–Ω–æ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –≤–∏—è–≤–ª–µ–Ω–Ω—è
                vad_parameters=dict(
                    min_silence_duration_ms=300,
                    speech_pad_ms=100,
                ),
                temperature=0.0,
                best_of=1,
            )
            
            segments_list = []
            full_text = ""
            
            for segment in segments:
                segment_dict = {
                    "start": segment.start,
                    "end": segment.end,
                    "text": segment.text.strip()
                }
                segments_list.append(segment_dict)
                full_text += segment.text + " "
            
            return {
                "text": full_text.strip(),
                "segments": segments_list,
                "duration": info.duration,
                "language": language
            }
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ worker —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó: {e}")
            return {
                "text": "",
                "segments": [],
                "duration": 0,
                "language": language
            }

"""
–û—Å–Ω–æ–≤–Ω–∏–π —Å–µ—Ä–≤—ñ—Å –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ—ó —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∞—É–¥—ñ–æ –∑ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–æ—é –∫–æ—Ä–µ–∫—Ü—ñ—î—é
"""

import os
import logging
import numpy as np
from typing import Dict, Any, Optional, List, Tuple
import torch
import librosa
import soundfile as sf
import asyncio
import time

from .config import logger, LANGUAGE_TOOL_AVAILABLE, SPEED_OPTIMIZED_CHUNK_SIZES, SUPPORTED_MODELS, ENABLE_DIARIZATION, DIARIZATION_MAX_WORKERS
from .whisper_model import LocalWhisperModel
from .diarization import SimpleDiarizationService

class LocalTranscriptionService:
    """–°–µ—Ä–≤—ñ—Å –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ—ó —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∞—É–¥—ñ–æ –∑ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–æ—é –∫–æ—Ä–µ–∫—Ü—ñ—î—é"""
    
    def __init__(self):
        self.models_loaded = False
        self.whisper_model = None
        self.diarization_service = None
        self.language_tool = None
        
        # –ö–µ—à—É–≤–∞–Ω–Ω—è —Ç–∏–º—á–∞—Å–æ–≤–æ –≤–∏–º–∫–Ω–µ–Ω–æ
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ LanguageTool –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏ (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
        if LANGUAGE_TOOL_AVAILABLE:
            try:
                import language_tool_python
                self.language_tool = language_tool_python.LanguageTool('uk-UA')
                logger.info("LanguageTool —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏")
            except Exception as e:
                logger.warning(f"LanguageTool –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π (–ø–æ—Ç—Ä—ñ–±–µ–Ω Java): {e}")
                self.language_tool = None
        else:
            logger.info("LanguageTool –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–π - –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è –≤–∏–º–∫–Ω–µ–Ω–∞")
        
    def load_models(self, model_size: str = "auto") -> bool:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –≤—Å—ñ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –º–æ–¥–µ–ª—ñ"""
        try:
            logger.info("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ª–æ–∫–∞–ª—å–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π...")
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø—Ä–∏—Å—Ç—Ä—ñ–π
            device = "cuda" if torch.cuda.is_available() else "cpu"
            logger.info(f"–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø—Ä–∏—Å—Ç—Ä—ñ–π: {device}")
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ä–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª—ñ (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞ 8GB RAM + 4 CPU AMD)
            if model_size == "auto":
                # –î–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∑–≤–∏—á–∞–π–Ω—ñ –º–æ–¥–µ–ª—ñ (distil —Ç—ñ–ª—å–∫–∏ –¥–ª—è –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—ó)
                try:
                    import psutil
                    memory_gb = psutil.virtual_memory().total / (1024**3)
                    cpu_count = psutil.cpu_count()
                    
                    if device == "cuda":
                        # –î–ª—è GPU –º–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –±—ñ–ª—å—à—ñ –º–æ–¥–µ–ª—ñ
                        try:
                            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                            
                            if gpu_memory >= 8:  # 8GB+ GPU
                                model_size = "medium"  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è GPU
                                logger.info(f"üöÄ GPU {gpu_memory:.1f}GB + RAM {memory_gb:.1f}GB - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è medium –º–æ–¥–µ–ª—å")
                            elif gpu_memory >= 4:  # 4GB+ GPU
                                model_size = "small"  # –ë–µ–∑–ø–µ—á–Ω–æ –¥–ª—è GPU
                                logger.info(f"üöÄ GPU {gpu_memory:.1f}GB + RAM {memory_gb:.1f}GB - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è small –º–æ–¥–µ–ª—å")
                            else:
                                model_size = "base"  # –î–ª—è –º–∞–ª–∏—Ö GPU
                                logger.info(f"üöÄ GPU {gpu_memory:.1f}GB + RAM {memory_gb:.1f}GB - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è base –º–æ–¥–µ–ª—å")
                        except:
                            model_size = "small"  # Fallback –¥–ª—è GPU
                    else:
                        # –î–ª—è CPU –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ small –º–æ–¥–µ–ª—å
                        if memory_gb >= 8 and cpu_count >= 4:
                            model_size = "small"  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ –Ω–∞ 8GB RAM
                            logger.info(f"üöÄ –°–µ—Ä–≤–µ—Ä {memory_gb:.1f}GB RAM + {cpu_count} CPU - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è small –º–æ–¥–µ–ª—å (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ)")
                        elif memory_gb >= 6:
                            model_size = "small"  # –ë–µ–∑–ø–µ—á–Ω–æ –¥–ª—è 6GB+ RAM
                            logger.info(f"üíæ –°–µ—Ä–≤–µ—Ä {memory_gb:.1f}GB RAM - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è small –º–æ–¥–µ–ª—å")
                        else:
                            model_size = "base"  # –î–ª—è –º–µ–Ω—à–∏—Ö —Å–µ—Ä–≤–µ—Ä—ñ–≤
                            logger.info(f"üíæ –°–µ—Ä–≤–µ—Ä {memory_gb:.1f}GB RAM - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è base –º–æ–¥–µ–ª—å")
                except:
                    model_size = "small"
            elif model_size not in SUPPORTED_MODELS:
                # –Ø–∫—â–æ –≤–∫–∞–∑–∞–Ω–æ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π —Ä–æ–∑–º—ñ—Ä, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ small
                logger.warning(f"–ù–µ–≤—ñ–¥–æ–º–∏–π —Ä–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª—ñ: {model_size}, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è small")
                model_size = "small"
            logger.info(f"–û–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏: {model_size}")
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ Whisper –∑ –ø–æ—Å–∏–ª–∞–Ω–Ω—è–º –Ω–∞ —Å–µ—Ä–≤—ñ—Å –¥–ª—è –∫–µ—à—É–≤–∞–Ω–Ω—è
            self.whisper_model = LocalWhisperModel(model_size=model_size, device=device, transcription_service=self)
            if not self.whisper_model.load_model():
                return False
            
            # –î—ñ–∞—Ä–∏–∑–∞—Ü—ñ—è –±—É–¥–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —Ç—ñ–ª—å–∫–∏ –ø—Ä–∏ –ø–æ—Ç—Ä–µ–±—ñ (lazy loading)
            # self.diarization_service = SimpleDiarizationService(self)  # –í–∏–¥–∞–ª–µ–Ω–æ –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
            
            self.models_loaded = True
            logger.info("–í—Å—ñ –º–æ–¥–µ–ª—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ —É—Å–ø—ñ—à–Ω–æ")
            return True
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª–µ–π: {e}")
            return False
    
    def _load_audio_cached(self, audio_path: str) -> Tuple[np.ndarray, int]:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –∞—É–¥—ñ–æ –∑ –¥–∏—Å–∫—É (–∫–µ—à—É–≤–∞–Ω–Ω—è –≤–∏–º–∫–Ω–µ–Ω–æ)"""
        # –ö–µ—à—É–≤–∞–Ω–Ω—è –≤–∏–º–∫–Ω–µ–Ω–æ - –∑–∞–≤–∂–¥–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑ –¥–∏—Å–∫—É
        logger.debug(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ –∑ –¥–∏—Å–∫—É: {audio_path}")
        audio, sr = librosa.load(audio_path, sr=16000, mono=True)
        return audio, sr
    
    def _correct_text(self, text: str, language: str) -> str:
        """–û—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è —Ç–µ–∫—Å—Ç—É –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏"""
        if not text or language != "uk" or not self.language_tool:
            return text
        
        try:
            # –í–∏–ø—Ä–∞–≤–ª—è—î–º–æ –ø–æ–º–∏–ª–∫–∏ —á–µ—Ä–µ–∑ LanguageTool
            matches = self.language_tool.check(text)
            import language_tool_python
            corrected_text = language_tool_python.utils.correct(text, matches)
            
            if corrected_text != text:
                logger.info("–ó–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω—É –∫–æ—Ä–µ–∫—Ü—ñ—é")
            
            return corrected_text
            
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–æ—ó –∫–æ—Ä–µ–∫—Ü—ñ—ó: {e}")
            return text
    
    def transcribe_simple(self, audio_path: str, language: str = "uk", use_parallel: bool = True, force_no_chunks: bool = True) -> Dict[str, Any]:
        """–®–≤–∏–¥–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –∑ –æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–∏–º –ø–∞—Ä–∞–ª–µ–ª—å–Ω–∏–º –æ–±—Ä–æ–±–ª–µ–Ω–Ω—è–º"""
        if not self.models_loaded:
            raise RuntimeError("–ú–æ–¥–µ–ª—ñ –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ")
        
        start_time = time.time()
        try:
            logger.info("–ü–æ—á–∞—Ç–æ–∫ —à–≤–∏–¥–∫–æ—ó —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∑ faster-whisper...")
            
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–∞—Ä–∞–ª–µ–ª—å–Ω—É –æ–±—Ä–æ–±–∫—É –¥–ª—è —Ñ–∞–π–ª—ñ–≤ –¥–æ–≤—à–∏—Ö –∑–∞ 2 —Ö–≤–∏–ª–∏–Ω–∏ (–¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ)
            if use_parallel:
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å —Ñ–∞–π–ª—É
                try:
                    import librosa
                    duration = librosa.get_duration(path=audio_path)
                    if duration > 60:  # –ü–æ—Ä—ñ–≥ 1 —Ö–≤–∏–ª–∏–Ω–∞ –¥–ª—è —à–≤–∏–¥–∫–æ—ó –æ–±—Ä–æ–±–∫–∏
                        logger.info(f"–§–∞–π–ª –¥–æ–≤–∂–∏–Ω–æ—é {duration:.1f}—Å - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞")
                        import asyncio
                        try:
                            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –≤–∂–µ —î –∑–∞–ø—É—â–µ–Ω–∏–π event loop
                            loop = asyncio.get_running_loop()
                            # –Ø–∫—â–æ —î, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—É –æ–±—Ä–æ–±–∫—É (–±–µ–∑ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è)
                            logger.info("Event loop –∞–∫—Ç–∏–≤–Ω–∏–π, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–∞ –æ–±—Ä–æ–±–∫–∞")
                            transcription_result = self.whisper_model.transcribe(audio_path, language)
                        except RuntimeError:
                            # –ù–µ–º–∞—î –∑–∞–ø—É—â–µ–Ω–æ–≥–æ loop, —Å—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤–∏–π
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                            try:
                                # –ü–µ—Ä–µ–¥–∞—î–º–æ –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –≤–∏–º–∫–Ω–µ–Ω–Ω—è —á–∞–Ω–∫—ñ–≤
                                transcription_result = loop.run_until_complete(
                                    self.whisper_model.transcribe_parallel(audio_path, language, None, force_no_chunks)
                                )
                            finally:
                                loop.close()
                    else:
                        logger.info(f"–§–∞–π–ª –∫–æ—Ä–æ—Ç–∫–∏–π ({duration:.1f}—Å) - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–∞ –æ–±—Ä–æ–±–∫–∞")
                        transcription_result = self.whisper_model.transcribe(audio_path, language)
                except Exception as e:
                    logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ç—Ä–∏–≤–∞–ª–æ—Å—Ç—ñ: {e}, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–∞ –æ–±—Ä–æ–±–∫–∞")
                    transcription_result = self.whisper_model.transcribe(audio_path, language)
            else:
                transcription_result = self.whisper_model.transcribe(audio_path, language)
            
            # –û–±—Ä–æ–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –∑ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–æ—é –∫–æ—Ä–µ–∫—Ü—ñ—î—é
            processed_result = self._process_simple_results(transcription_result, language)
            
            elapsed_time = time.time() - start_time
            logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø—ñ—à–Ω–æ –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")
            return processed_result
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó: {e}")
            raise
    
    def transcribe_with_diarization(self, audio_path: str, language: str = "uk", use_parallel: bool = True, force_no_chunks: bool = True) -> Dict[str, Any]:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –∑ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—î—é (–û–ø–µ—Ä–∞—Ç–æ—Ä/–ö–ª—ñ—î–Ω—Ç) –∑ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—é –æ–±—Ä–æ–±–∫–æ—é"""
        if not self.models_loaded:
            raise RuntimeError("–ú–æ–¥–µ–ª—ñ –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ")
        
        # Lazy loading –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó - —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –ø—Ä–∏ –ø–æ—Ç—Ä–µ–±—ñ
        if not ENABLE_DIARIZATION:
            logger.warning("‚ö†Ô∏è –î—ñ–∞—Ä–∏–∑–∞—Ü—ñ—è –≤—ñ–¥–∫–ª—é—á–µ–Ω–∞ –≤ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó")
            raise RuntimeError("–î—ñ–∞—Ä–∏–∑–∞—Ü—ñ—è –≤—ñ–¥–∫–ª—é—á–µ–Ω–∞ –≤ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó")
        
        if self.diarization_service is None:
            logger.info("üîß –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó (lazy loading)...")
            self.diarization_service = SimpleDiarizationService(self)
        
        start_time = time.time()
        try:
            logger.info("–ü–æ—á–∞—Ç–æ–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∑ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—î—é...")
            
            # –°–ø–æ—á–∞—Ç–∫—É –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —Ñ–∞–π–ª (—è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ) —Ç–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∞—É–¥—ñ–æ
            processed_audio_path = self.whisper_model._convert_to_optimal_format(audio_path)
            logger.info(f"üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–∏–π —Ñ–∞–π–ª: {processed_audio_path}")
            logger.info("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ –¥–ª—è –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó...")
            audio, sr = self._load_audio_cached(processed_audio_path)
            
            # –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∞—É–¥—ñ–æ
            audio_duration = len(audio) / sr
            logger.info(f"üìä –ê—É–¥—ñ–æ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å={audio_duration:.2f}—Å, —á–∞—Å—Ç–æ—Ç–∞={sr}Hz, –∑—Ä–∞–∑–∫—ñ–≤={len(audio)}")
            logger.info(f"üìä –ü–µ—Ä—à—ñ 0.5—Å –∞—É–¥—ñ–æ: min={audio[:int(0.5*sr)].min():.4f}, max={audio[:int(0.5*sr)].max():.4f}, rms={np.sqrt(np.mean(audio[:int(0.5*sr)]**2)):.4f}")
            
            # –†–æ–±–∏–º–æ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—é –∑ –∫–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–∏–º —Ñ–∞–π–ª–æ–º
            speaker_segments = self.diarization_service.process_audio(processed_audio_path)
            
            if not speaker_segments:
                logger.warning("–î—ñ–∞—Ä–∏–∑–∞—Ü—ñ—è –Ω–µ –∑–Ω–∞–π—à–ª–∞ —Å–µ–≥–º–µ–Ω—Ç–∏, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø—Ä–æ—Å—Ç—É —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—é")
                return self.transcribe_simple(audio_path, language, use_parallel)
            
            if use_parallel and len(speaker_segments) > 1:
                # –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –∑ ProcessPoolExecutor
                logger.info(f"–ü–∞—Ä–∞–ª–µ–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ {len(speaker_segments)} —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó...")
                processed_segments = self._process_diarization_segments_parallel(
                    audio, sr, speaker_segments, language
                )
            else:
                # –ü–æ—Å–ª—ñ–¥–æ–≤–Ω–∞ –æ–±—Ä–æ–±–∫–∞ (fallback)
                processed_segments = self._process_diarization_segments_sequential(
                    audio, sr, speaker_segments, language
                )
            
            # –ü—ñ–¥—Ä–∞—Ö–æ–≤—É—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–∏–∫—Ç–æ—Ä–∞—Ö
            speakers_stats = {}
            full_text = ""
            
            # –°–æ—Ä—Ç—É—î–º–æ —Å–µ–≥–º–µ–Ω—Ç–∏ –∑–∞ —á–∞—Å–æ–º –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫—É
            processed_segments.sort(key=lambda x: x["start"])
            
            for segment in processed_segments:
                speaker = segment["speaker"]
                if speaker not in speakers_stats:
                    speakers_stats[speaker] = {
                        "speaker": speaker,
                        "segments_count": 0,
                        "total_duration": 0,
                        "first_segment": segment["start"],
                        "last_segment": segment["end"]
                    }
                
                speakers_stats[speaker]["segments_count"] += 1
                speakers_stats[speaker]["total_duration"] += segment["duration"]
                speakers_stats[speaker]["last_segment"] = max(speakers_stats[speaker]["last_segment"], segment["end"])
                
                # –î–æ–¥–∞—î–º–æ —á–∞—Å –¥–æ —Ç–µ–∫—Å—Ç—É –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è
                time_info = f"[{segment['start']:.1f}s-{segment['end']:.1f}s]"
                full_text += f"{time_info} [{speaker}]: {segment['text']}\n"
            
            result = {
                "text": full_text.strip(),
                "segments": processed_segments,
                "speakers": list(speakers_stats.values()),
                "duration": max([s["end"] for s in processed_segments]) if processed_segments else 0,
                "language": language,
                "diarization_type": "simple_alternating_parallel" if use_parallel else "simple_alternating"
            }
            
            elapsed_time = time.time() - start_time
            logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –∑ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—î—é –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(processed_segments)} —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")
            return result
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∑ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—î—é: {e}")
            raise
    
    def _process_diarization_segments_parallel(self, audio: np.ndarray, sr: int, 
                                             speaker_segments: List[Dict[str, Any]], 
                                             language: str) -> List[Dict[str, Any]]:
        """–ü–∞—Ä–∞–ª–µ–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó –∑ ProcessPoolExecutor"""
        try:
            import asyncio
            from concurrent.futures import ProcessPoolExecutor
            import os
            
            # –î–∏–Ω–∞–º—ñ—á–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –ø—Ä–æ—Ü–µ—Å—ñ–≤ (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞ 8GB RAM + 4 CPU AMD)
            cpu_count = os.cpu_count()
            # –û–±–º–µ–∂—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—ñ–≤ –¥–ª—è –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó (–º–µ–Ω—à–µ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è)
            max_workers = min(DIARIZATION_MAX_WORKERS, len(speaker_segments), cpu_count // 2)  # –¢—ñ–ª—å–∫–∏ 50% CPU –¥–ª—è –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó
            logger.info(f"üöÄ –°–µ—Ä–≤–µ—Ä {cpu_count} CPU AMD - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è {max_workers} –ø—Ä–æ—Ü–µ—Å—ñ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—ó –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ)")
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ –∑–∞–≤–¥–∞–Ω–Ω—è –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç—É
            with ProcessPoolExecutor(max_workers=max_workers) as executor:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                tasks = [
                    loop.run_in_executor(
                        executor, 
                        self._process_single_diarization_segment_worker,
                        audio, sr, segment, language
                    )
                    for segment in speaker_segments
                ]
                
                # –ß–µ–∫–∞—î–º–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –≤—Å—ñ—Ö –∑–∞–≤–¥–∞–Ω—å
                results = loop.run_until_complete(asyncio.gather(*tasks))
                loop.close()
            
            # –§—ñ–ª—å—Ç—Ä—É—î–º–æ —É—Å–ø—ñ—à–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
            processed_segments = [result for result in results if result is not None]
            
            logger.info(f"–ü–∞—Ä–∞–ª–µ–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(processed_segments)}/{len(speaker_segments)} —Å–µ–≥–º–µ–Ω—Ç—ñ–≤")
            return processed_segments
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó: {e}")
            # Fallback –¥–æ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏
            return self._process_diarization_segments_sequential(audio, sr, speaker_segments, language)
    
    @staticmethod
    def _process_single_diarization_segment_worker(audio: np.ndarray, sr: int,
                                                 speaker_info: Dict[str, Any], 
                                                 language: str) -> Optional[Dict[str, Any]]:
        """Worker —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è ProcessPoolExecutor (—Å—Ç–∞—Ç–∏—á–Ω–∏–π –º–µ—Ç–æ–¥)"""
        try:
            # –Ü–º–ø–æ—Ä—Ç—É—î–º–æ —Ç—É—Ç, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –ø—Ä–æ–±–ª–µ–º –∑ multiprocessing
            from faster_whisper import WhisperModel
            import torch
            
            start_time = speaker_info["start"]
            end_time = speaker_info["end"]
            speaker = speaker_info["speaker"]
            
            # –í–∏—Ç—è–≥—É—î–º–æ —Å–µ–≥–º–µ–Ω—Ç –∞—É–¥—ñ–æ –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ–≥–æ –º–∞—Å–∏–≤—É
            start_sample = int(start_time * sr)
            end_sample = int(end_time * sr)
            segment_audio = audio[start_sample:end_sample]
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø—Ä–∏—Å—Ç—Ä—ñ–π —Ç–∞ compute_type (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞ 8GB RAM + 4 CPU AMD)
            device = "cuda" if torch.cuda.is_available() else "cpu"
            if device == "cpu":
                try:
                    import psutil
                    memory_gb = psutil.virtual_memory().total / (1024**3)
                    cpu_count = psutil.cpu_count()
                    
                    if memory_gb >= 8 and cpu_count >= 4:
                        compute_type = "int8_float16"  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è –≤–∞—à–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
                    elif memory_gb >= 8:
                        compute_type = "int8_float16"  # –®–≤–∏–¥—à–µ –Ω—ñ–∂ int8
                    else:
                        compute_type = "int8"  # –ï–∫–æ–Ω–æ–º–Ω—ñ—à–µ –ø–æ –ø–∞–º'—è—Ç—ñ
                except:
                    compute_type = "int8"
            else:
                compute_type = "float16"
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å –≤ worker –ø—Ä–æ—Ü–µ—Å—ñ
            model = WhisperModel("small", device=device, compute_type=compute_type)
            
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É—î–º–æ —Å–µ–≥–º–µ–Ω—Ç –∑ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            segments, info = model.transcribe(
                segment_audio,
                language=language,
                beam_size=1,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ —à–≤–∏–¥–∫—ñ—Å—Ç—å
                word_timestamps=True,
                vad_filter=True,  # –£–í–Ü–ú–ö–ù–ï–ù–û –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –≤–∏—è–≤–ª–µ–Ω–Ω—è –ø–æ—á–∞—Ç–∫—É –º–æ–≤–ª–µ–Ω–Ω—è
                vad_parameters=dict(
                    min_silence_duration_ms=300,  # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å —Ç–∏—à—ñ
                    speech_pad_ms=100,  # –ë—É—Ñ–µ—Ä –Ω–∞–≤–∫–æ–ª–æ –º–æ–≤–ª–µ–Ω–Ω—è
                ),
                temperature=0.0,
                best_of=1,
            )
            
            # –û–±—Ä–æ–±–ª—è—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            segment_text = ""
            for segment in segments:
                segment_text += segment.text + " "
            
            if segment_text.strip():
                return {
                    "start": start_time,
                    "end": end_time,
                    "text": segment_text.strip(),
                    "speaker": speaker,
                    "duration": end_time - start_time
                }
            
            return None
            
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ worker –æ–±—Ä–æ–±–∫–∏ —Å–µ–≥–º–µ–Ω—Ç—É {speaker}: {e}")
            return None
    
    def _process_diarization_segments_sequential(self, audio: np.ndarray, sr: int,
                                               speaker_segments: List[Dict[str, Any]], 
                                               language: str) -> List[Dict[str, Any]]:
        """–ü–æ—Å–ª—ñ–¥–æ–≤–Ω–∞ –æ–±—Ä–æ–±–∫–∞ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó (fallback)"""
        processed_segments = []
        
        for speaker_info in speaker_segments:
            try:
                result = self._process_single_diarization_segment(audio, sr, speaker_info, language)
                if result:
                    processed_segments.append(result)
            except Exception as e:
                logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —Å–µ–≥–º–µ–Ω—Ç—É {speaker_info.get('speaker', 'unknown')}: {e}")
                continue
        
        return processed_segments
    
    def _process_single_diarization_segment(self, audio: np.ndarray, sr: int,
                                          speaker_info: Dict[str, Any], 
                                          language: str) -> Optional[Dict[str, Any]]:
        """–û–±—Ä–æ–±–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç—É –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó"""
        try:
            start_time = speaker_info["start"]
            end_time = speaker_info["end"]
            speaker = speaker_info["speaker"]
            
            # –í–∏—Ç—è–≥—É—î–º–æ —Å–µ–≥–º–µ–Ω—Ç –∞—É–¥—ñ–æ –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ–≥–æ –º–∞—Å–∏–≤—É
            start_sample = int(start_time * sr)
            end_sample = int(end_time * sr)
            segment_audio = audio[start_sample:end_sample]
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤–∏–π —Ñ–∞–π–ª –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç—É
            segment_path = f"temp_segment_{start_time:.1f}_{end_time:.1f}.wav"
            sf.write(segment_path, segment_audio, sr, format='WAV', subtype='PCM_16')
            
            try:
                # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É—î–º–æ —Å–µ–≥–º–µ–Ω—Ç –∑ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                segment_duration = end_time - start_time
                if segment_duration < 10:  # –î—É–∂–µ –∫–æ—Ä–æ—Ç–∫—ñ —Å–µ–≥–º–µ–Ω—Ç–∏
                    beam_size = 1
                    vad_filter = False
                elif segment_duration < 30:
                    beam_size = 1
                    vad_filter = True
                else:
                    beam_size = 2
                    vad_filter = True
                
                # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
                segments, info = self.whisper_model.model.transcribe(
                    segment_path,
                    language=language,
                    beam_size=beam_size,
                    word_timestamps=True,
                    vad_filter=True,  # –ó–∞–≤–∂–¥–∏ —É–≤—ñ–º–∫–Ω–µ–Ω–æ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –≤–∏—è–≤–ª–µ–Ω–Ω—è
                    vad_parameters=dict(
                        min_silence_duration_ms=200,  # –ó–º–µ–Ω—à–µ–Ω–æ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –≤–∏—è–≤–ª–µ–Ω–Ω—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø–∞—É–∑
                        speech_pad_ms=150,  # –ë—É—Ñ–µ—Ä –Ω–∞–≤–∫–æ–ª–æ –º–æ–≤–ª–µ–Ω–Ω—è
                    ),
                )
                
                # –û–±—Ä–æ–±–ª—è—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                segment_text = ""
                for segment in segments:
                    segment_text += segment.text + " "
                
                segment_result = {
                    "text": segment_text.strip(),
                    "segments": [{"start": s.start, "end": s.end, "text": s.text} for s in segments],
                    "duration": info.duration,
                    "language": language
                }
                
                # –û–±—Ä–æ–±–ª—è—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                if segment_result and segment_result.get("text"):
                    segment_text = segment_result["text"].strip()
                    
                    # –û—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è
                    if language == "uk":
                        segment_text = self._correct_text(segment_text, language)
                    
                    return {
                        "start": start_time,
                        "end": end_time,
                        "text": segment_text,
                        "speaker": speaker,
                        "duration": end_time - start_time
                    }
                
                return None
                
            finally:
                # –í–∏–¥–∞–ª—è—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤–∏–π —Ñ–∞–π–ª
                try:
                    os.unlink(segment_path)
                except:
                    pass
                    
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —Å–µ–≥–º–µ–Ω—Ç—É {speaker}: {e}")
            return None
    
    def _process_simple_results(self, transcription_result: Dict[str, Any], language: str) -> Dict[str, Any]:
        """–û–±—Ä–æ–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –ø—Ä–æ—Å—Ç–æ—ó —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∑ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–æ—é –∫–æ—Ä–µ–∫—Ü—ñ—î—é"""
        try:
            if not transcription_result or not transcription_result.get("text"):
                return {
                    "text": "–¢–µ–∫—Å—Ç –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ - –∞—É–¥—ñ–æ –º–æ–∂–µ –±—É—Ç–∏ –±–µ–∑ –º–æ–≤–ª–µ–Ω–Ω—è –∞–±–æ –∑–∞–Ω–∞–¥—Ç–æ —Ç–∏—Ö–∏–º",
                    "segments": [],
                    "duration": 0,
                    "language": language
                }
            
            # –û—Ç—Ä–∏–º—É—î–º–æ —Ç–µ–∫—Å—Ç
            text = transcription_result.get("text", "").strip()
            
            # –ü–µ—Ä–µ–∫–æ–Ω—É—î–º–æ—Å—è, —â–æ —Ç–µ–∫—Å—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∫–æ–¥—É—î—Ç—å—Å—è –≤ UTF-8
            if isinstance(text, bytes):
                text = text.decode('utf-8', errors='ignore')
            
            # –û—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏
            if language == "uk":
                text = self._correct_text(text, language)
            
            # –û—Ç—Ä–∏–º—É—î–º–æ —Å–µ–≥–º–µ–Ω—Ç–∏ –∑ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–æ—é –∫–æ—Ä–µ–∫—Ü—ñ—î—é
            segments = []
            for segment in transcription_result.get("segments", []):
                segment_text = segment.get("text", "").strip()
                
                # –ü–µ—Ä–µ–∫–æ–Ω—É—î–º–æ—Å—è, —â–æ —Ç–µ–∫—Å—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∫–æ–¥—É—î—Ç—å—Å—è –≤ UTF-8
                if isinstance(segment_text, bytes):
                    segment_text = segment_text.decode('utf-8', errors='ignore')
                
                # –û—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç—É
                if language == "uk":
                    segment_text = self._correct_text(segment_text, language)
                
                segments.append({
                    "start": segment.get("start", 0),
                    "end": segment.get("end", 0),
                    "text": segment_text
                })
            
            # –û—Ç—Ä–∏–º—É—î–º–æ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å
            duration = transcription_result.get("duration", 0)
            
            return {
                "text": text,
                "segments": segments,
                "duration": duration,
                "language": language
            }
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤: {e}")
            return {
                "text": "–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó",
                "segments": [],
                "duration": 0,
                "language": language
            }

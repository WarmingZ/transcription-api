"""
–û—Å–Ω–æ–≤–Ω–∏–π —Å–µ—Ä–≤—ñ—Å –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ—ó —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∞—É–¥—ñ–æ –∑ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–æ—é –∫–æ—Ä–µ–∫—Ü—ñ—î—é
"""

import os
import logging
import numpy as np
from typing import Dict, Any, Optional, List, Tuple
import torch
import librosa
import soundfile as sf
import time
import hashlib

from .config import logger, LANGUAGE_TOOL_AVAILABLE, SUPPORTED_MODELS, QUANTIZED_MODELS, ENABLE_DIARIZATION, DIARIZATION_MAX_WORKERS, MAX_FILE_SIZE_MB, MAX_AUDIO_DURATION_MINUTES, MEMORY_PRESSURE_THRESHOLD
from .whisper_model import LocalWhisperModel
from .diarization import SimpleDiarizationService

# –Ü–º–ø–æ—Ä—Ç –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É –ø–∞–º'—è—Ç—ñ
try:
    from memory_monitor import memory_monitor
    MEMORY_MONITOR_AVAILABLE = True
except ImportError:
    MEMORY_MONITOR_AVAILABLE = False
    logger.warning("–ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º'—è—Ç—ñ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π")

class LocalTranscriptionService:
    """–°–µ—Ä–≤—ñ—Å –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ—ó —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∞—É–¥—ñ–æ –∑ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–æ—é –∫–æ—Ä–µ–∫—Ü—ñ—î—é"""
    
    def __init__(self, beam_size: int = 1, best_of: int = 1, word_timestamps: bool = True):
        self.models_loaded = False
        self.whisper_model = None
        self.diarization_service = None
        self.language_tool = None
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ
        self.beam_size = beam_size
        self.best_of = best_of
        self.word_timestamps = word_timestamps
        
        # –ö–µ—à—É–≤–∞–Ω–Ω—è –∞—É–¥—ñ–æ –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó (–º—ñ–Ω—ñ–º—ñ–∑–æ–≤–∞–Ω–æ –¥–ª—è –µ–∫–æ–Ω–æ–º—ñ—ó –ø–∞–º'—è—Ç—ñ)
        self._audio_cache = {}
        self._cache_max_size = 2  # –ú–∞–∫—Å–∏–º—É–º 2 —Ñ–∞–π–ª–∏ –≤ –∫–µ—à—ñ (–º—ñ–Ω—ñ–º—ñ–∑–æ–≤–∞–Ω–æ –¥–ª—è –µ–∫–æ–Ω–æ–º—ñ—ó –ø–∞–º'—è—Ç—ñ)
        
        # –ö–µ—à—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ LanguageTool –¥–ª—è —É–Ω–∏–∫–Ω–µ–Ω–Ω—è –ø–æ–≤—Ç–æ—Ä–Ω–∏—Ö –ø–µ—Ä–µ–≤—ñ—Ä–æ–∫
        self._language_tool_cache = {}
        self._lt_cache_max_size = 25  # –ú–∞–∫—Å–∏–º—É–º 25 —Ç–µ–∫—Å—Ç—ñ–≤ –≤ –∫–µ—à—ñ LanguageTool (–º—ñ–Ω—ñ–º—ñ–∑–æ–≤–∞–Ω–æ)
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ LanguageTool –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏ (–æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ)
        if LANGUAGE_TOOL_AVAILABLE:
            try:
                import language_tool_python
                # –û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞ 8 CPU + 14GB RAM
                self.language_tool = language_tool_python.LanguageTool(
                    'uk-UA',
                    config={
                        'maxSpellingSuggestions': 3,  # –ú–µ–Ω—à–µ –ø—Ä–æ–ø–æ–∑–∏—Ü—ñ–π = —à–≤–∏–¥—à–µ
                        'maxErrorsPerWordRate': 0.3,  # –û–±–º–µ–∂—É—î–º–æ –ø–æ–º–∏–ª–∫–∏
                        'maxLength': 10000,  # –û–±–º–µ–∂—É—î–º–æ –¥–æ–≤–∂–∏–Ω—É —Ç–µ–∫—Å—Ç—É
                    }
                )
                logger.info("LanguageTool —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏ (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ)")
            except Exception as e:
                logger.warning(f"LanguageTool –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π (–ø–æ—Ç—Ä—ñ–±–µ–Ω Java): {e}")
                self.language_tool = None
        else:
            logger.info("LanguageTool –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–π - –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è –≤–∏–º–∫–Ω–µ–Ω–∞")
        
    def load_models(self, model_size: str = "auto") -> bool:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –≤—Å—ñ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –º–æ–¥–µ–ª—ñ"""
        try:
            logger.info("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ª–æ–∫–∞–ª—å–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π...")
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø—Ä–∏—Å—Ç—Ä—ñ–π
            device = "cuda" if torch.cuda.is_available() else "cpu"
            logger.info(f"–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø—Ä–∏—Å—Ç—Ä—ñ–π: {device}")
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ä–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª—ñ (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞ 14GB RAM + 8 CPU)
            if model_size == "auto":
                # –î–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∑–≤–∏—á–∞–π–Ω—ñ –º–æ–¥–µ–ª—ñ (distil —Ç—ñ–ª—å–∫–∏ –¥–ª—è –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—ó)
                try:
                    import psutil
                    memory_gb = psutil.virtual_memory().total / (1024**3)
                    cpu_count = psutil.cpu_count()
                    
                    if device == "cuda":
                        # –î–ª—è GPU –º–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –±—ñ–ª—å—à—ñ –º–æ–¥–µ–ª—ñ
                        try:
                            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                            
                            if gpu_memory >= 8:  # 8GB+ GPU
                                model_size = "medium"  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è GPU
                                logger.info(f"üöÄ GPU {gpu_memory:.1f}GB + RAM {memory_gb:.1f}GB - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è medium –º–æ–¥–µ–ª—å")
                            elif gpu_memory >= 4:  # 4GB+ GPU
                                model_size = "small"  # –ë–µ–∑–ø–µ—á–Ω–æ –¥–ª—è GPU
                                logger.info(f"üöÄ GPU {gpu_memory:.1f}GB + RAM {memory_gb:.1f}GB - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è small –º–æ–¥–µ–ª—å")
                            else:
                                model_size = "base"  # –î–ª—è –º–∞–ª–∏—Ö GPU
                                logger.info(f"üöÄ GPU {gpu_memory:.1f}GB + RAM {memory_gb:.1f}GB - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è base –º–æ–¥–µ–ª—å")
                        except:
                            model_size = "small"  # Fallback –¥–ª—è GPU
                    else:
                        # –î–ª—è CPU –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ quantized –º–æ–¥–µ–ª—ñ (—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è ChatGPT)
                        if memory_gb >= 12 and cpu_count >= 8:
                            model_size = "medium"  # medium + int8 = quantized - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è –ø–æ—Ç—É–∂–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
                            logger.info(f"üöÄ –ü–æ—Ç—É–∂–Ω–∏–π —Å–µ—Ä–≤–µ—Ä {memory_gb:.1f}GB RAM + {cpu_count} CPU - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è medium –º–æ–¥–µ–ª—å (quantized)")
                        elif memory_gb >= 8 and cpu_count >= 6:
                            model_size = "small"  # small + int8 = quantized - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è CPU
                            logger.info(f"üöÄ –°–µ—Ä–≤–µ—Ä {memory_gb:.1f}GB RAM + {cpu_count} CPU - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è small –º–æ–¥–µ–ª—å (quantized)")
                        elif memory_gb >= 6:
                            model_size = "base"  # base + int8 = quantized
                            logger.info(f"üíæ –°–µ—Ä–≤–µ—Ä {memory_gb:.1f}GB RAM - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è base –º–æ–¥–µ–ª—å (quantized)")
                        else:
                            model_size = "tiny"  # tiny + int8 = quantized –¥–ª—è –º–∞–ª–∏—Ö —Å–µ—Ä–≤–µ—Ä—ñ–≤
                            logger.info(f"üíæ –°–µ—Ä–≤–µ—Ä {memory_gb:.1f}GB RAM - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è tiny –º–æ–¥–µ–ª—å (quantized)")
                except:
                    model_size = "base"
            elif model_size not in SUPPORTED_MODELS:
                # –Ø–∫—â–æ –≤–∫–∞–∑–∞–Ω–æ –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π —Ä–æ–∑–º—ñ—Ä, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ base
                logger.warning(f"–ù–µ–≤—ñ–¥–æ–º–∏–π —Ä–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª—ñ: {model_size}, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è base")
                model_size = "base"
            # –ü–æ–∫–∞–∑—É—î–º–æ —â–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è quantized –º–æ–¥–µ–ª—å
            logger.info(f"–û–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏: {model_size} (quantized –∑ int8)")
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ Whisper –∑ –ø–æ—Å–∏–ª–∞–Ω–Ω—è–º –Ω–∞ —Å–µ—Ä–≤—ñ—Å –¥–ª—è –∫–µ—à—É–≤–∞–Ω–Ω—è
            self.whisper_model = LocalWhisperModel(model_size=model_size, device=device, transcription_service=self)
            if not self.whisper_model.load_model():
                return False
            
            # –î—ñ–∞—Ä–∏–∑–∞—Ü—ñ—è –±—É–¥–µ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ —Ç—ñ–ª—å–∫–∏ –ø—Ä–∏ –ø–æ—Ç—Ä–µ–±—ñ (lazy loading)
            # self.diarization_service = SimpleDiarizationService(self)  # –í–∏–¥–∞–ª–µ–Ω–æ –¥–ª—è –æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—ó
            
            self.models_loaded = True
            logger.info("–í—Å—ñ –º–æ–¥–µ–ª—ñ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ —É—Å–ø—ñ—à–Ω–æ")
            return True
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª–µ–π: {e}")
            return False
    
    def _load_audio_cached(self, audio_path: str) -> Tuple[np.ndarray, int]:
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –∞—É–¥—ñ–æ –∑ –∫–µ—à—É –∞–±–æ –∑ –¥–∏—Å–∫—É (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ –¥–ª—è –µ–∫–æ–Ω–æ–º—ñ—ó –ø–∞–º'—è—Ç—ñ)"""
        try:
            # –°—Ç–≤–æ—Ä—é—î–º–æ —Ö–µ—à —Ñ–∞–π–ª—É –¥–ª—è –∫–µ—à—É–≤–∞–Ω–Ω—è
            file_stat = os.stat(audio_path)
            file_hash = f"{audio_path}_{file_stat.st_size}_{file_stat.st_mtime}"
            
            if file_hash in self._audio_cache:
                logger.debug(f"–ê—É–¥—ñ–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∑ –∫–µ—à—É: {audio_path}")
                return self._audio_cache[file_hash]
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑ –¥–∏—Å–∫—É —Ç–∞ –∫–µ—à—É—î–º–æ (–∑ –µ–∫–æ–Ω–æ–º—ñ—î—é –ø–∞–º'—è—Ç—ñ)
            logger.debug(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∞—É–¥—ñ–æ –∑ –¥–∏—Å–∫—É: {audio_path}")
            audio, sr = librosa.load(audio_path, sr=16000, mono=True, dtype=np.float32)
            
            # –î–æ–¥–∞—î–º–æ –≤ –∫–µ—à (–∑ –æ–±–º–µ–∂–µ–Ω–Ω—è–º —Ä–æ–∑–º—ñ—Ä—É —Ç–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –æ—á–∏—â–µ–Ω–Ω—è–º)
            if len(self._audio_cache) >= self._cache_max_size:
                # –í–∏–¥–∞–ª—è—î–º–æ –Ω–∞–π—Å—Ç–∞—Ä—ñ—à–∏–π –µ–ª–µ–º–µ–Ω—Ç
                oldest_key = next(iter(self._audio_cache))
                del self._audio_cache[oldest_key]
                logger.debug(f"–û—á–∏—â–µ–Ω–æ —Å—Ç–∞—Ä–∏–π –∞—É–¥—ñ–æ –∫–µ—à: {oldest_key}")
            
            self._audio_cache[file_hash] = (audio, sr)
            return audio, sr
            
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –∫–µ—à—É–≤–∞–Ω–Ω—è –∞—É–¥—ñ–æ: {e}, –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑ –¥–∏—Å–∫—É")
            audio, sr = librosa.load(audio_path, sr=16000, mono=True, dtype=np.float32)
            return audio, sr
    
    def clear_audio_cache(self):
        """–û—á–∏—â—É—î –∫–µ—à –∞—É–¥—ñ–æ –¥–ª—è –µ–∫–æ–Ω–æ–º—ñ—ó –ø–∞–º'—è—Ç—ñ"""
        cache_size = len(self._audio_cache)
        self._audio_cache.clear()
        logger.info(f"–û—á–∏—â–µ–Ω–æ –∞—É–¥—ñ–æ –∫–µ—à: {cache_size} —Ñ–∞–π–ª—ñ–≤")
    
    def clear_language_tool_cache(self):
        """–û—á–∏—â—É—î –∫–µ—à LanguageTool –¥–ª—è –µ–∫–æ–Ω–æ–º—ñ—ó –ø–∞–º'—è—Ç—ñ"""
        cache_size = len(self._language_tool_cache)
        self._language_tool_cache.clear()
        logger.info(f"–û—á–∏—â–µ–Ω–æ LanguageTool –∫–µ—à: {cache_size} —Ç–µ–∫—Å—Ç—ñ–≤")
    
    def clear_all_caches(self):
        """–û—á–∏—â—É—î –≤—Å—ñ –∫–µ—à—ñ –¥–ª—è –µ–∫–æ–Ω–æ–º—ñ—ó –ø–∞–º'—è—Ç—ñ"""
        self.clear_audio_cache()
        self.clear_language_tool_cache()
        logger.info("–í—Å—ñ –∫–µ—à—ñ –æ—á–∏—â–µ–Ω–æ")
    
    def _correct_text(self, text: str, language: str) -> str:
        """–û—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è —Ç–µ–∫—Å—Ç—É –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏ –∑ –∫–µ—à—É–≤–∞–Ω–Ω—è–º"""
        if not text or language != "uk" or not self.language_tool:
            return text
        
        try:
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–µ—à (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–∏–π hash)
            import hashlib
            text_hash = hashlib.md5(text.encode("utf-8")).hexdigest()
            if text_hash in self._language_tool_cache:
                logger.debug("–û—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ –∑ –∫–µ—à—É")
                return self._language_tool_cache[text_hash]
            
            # –í–∏–ø—Ä–∞–≤–ª—è—î–º–æ –ø–æ–º–∏–ª–∫–∏ —á–µ—Ä–µ–∑ LanguageTool (–±–µ–∑–ø–µ—á–Ω–∏–π —Å–ø–æ—Å—ñ–±)
            matches = self.language_tool.check(text)
            corrected_text = text
            for match in reversed(matches):  # –û–±—Ä–æ–±–ª—è—î–º–æ –∑ –∫—ñ–Ω—Ü—è —â–æ–± –Ω–µ –∑–º—ñ–Ω—é–≤–∞—Ç–∏ —ñ–Ω–¥–µ–∫—Å–∏
                if match.replacements:
                    corrected_text = corrected_text[:match.offset] + match.replacements[0] + corrected_text[match.offset + match.errorLength:]
            
            # –ö–µ—à—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if len(self._language_tool_cache) >= self._lt_cache_max_size:
                # –í–∏–¥–∞–ª—è—î–º–æ –Ω–∞–π—Å—Ç–∞—Ä—ñ—à–∏–π –µ–ª–µ–º–µ–Ω—Ç
                oldest_key = next(iter(self._language_tool_cache))
                del self._language_tool_cache[oldest_key]
            
            self._language_tool_cache[text_hash] = corrected_text
            
            if corrected_text != text:
                logger.debug("–ó–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω—É –∫–æ—Ä–µ–∫—Ü—ñ—é")
            
            return corrected_text
            
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–æ—ó –∫–æ—Ä–µ–∫—Ü—ñ—ó: {e}")
            return text
    
    def _correct_text_batch(self, texts: List[str], language: str) -> List[str]:
        """–ü–∞–∫–µ—Ç–Ω–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è –ø–æ —Ä–µ—á–µ–Ω–Ω—è—Ö –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ"""
        if not texts or language != "uk" or not self.language_tool:
            return texts
        
        try:
            # –°–ø–æ—á–∞—Ç–∫—É –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–µ—à –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É
            cached_results = {}
            texts_to_process = []
            text_indices = []
            
            for i, text in enumerate(texts):
                if not text.strip():
                    cached_results[i] = text
                    continue
                
                import hashlib
                text_hash = hashlib.md5(text.encode("utf-8")).hexdigest()
                if text_hash in self._language_tool_cache:
                    cached_results[i] = self._language_tool_cache[text_hash]
                else:
                    texts_to_process.append(text)
                    text_indices.append(i)
            
            # –Ø–∫—â–æ –≤—Å—ñ —Ç–µ–∫—Å—Ç–∏ –≤ –∫–µ—à—ñ, –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
            if not texts_to_process:
                logger.debug("–í—Å—ñ —Ç–µ–∫—Å—Ç–∏ –∑–Ω–∞–π–¥–µ–Ω—ñ –≤ –∫–µ—à—ñ LanguageTool")
                return [cached_results[i] for i in range(len(texts))]
            
            # –†–æ–∑–±–∏–≤–∞—î–º–æ —Ç–µ–∫—Å—Ç–∏ –Ω–∞ —Ä–µ—á–µ–Ω–Ω—è —Ç–∞ –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –º–∞–ø—ñ–Ω–≥
            sentence_mapping = []  # [(original_text_index, sentence_start, sentence_end), ...]
            all_sentences = []
            
            for text_idx, text in enumerate(texts_to_process):
                # –†–æ–∑–±–∏–≤–∞—î–º–æ –Ω–∞ —Ä–µ—á–µ–Ω–Ω—è (–ø—Ä–æ—Å—Ç–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º)
                sentences = self._split_into_sentences(text)
                
                for sentence in sentences:
                    if sentence.strip():
                        sentence_mapping.append((text_idx, len(all_sentences)))
                        all_sentences.append(sentence.strip())
            
            if not all_sentences:
                return texts
            
            # –û–±–º–µ–∂—É—î–º–æ —Ä–æ–∑–º—ñ—Ä —Ç–µ–∫—Å—Ç—É –¥–ª—è LanguageTool (–º–∞–∫—Å–∏–º—É–º 5000 —Å–∏–º–≤–æ–ª—ñ–≤)
            max_chunk_size = 5000
            if len(" ".join(all_sentences)) > max_chunk_size:
                logger.debug(f"–¢–µ–∫—Å—Ç –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏–π ({len(' '.join(all_sentences))} —Å–∏–º–≤–æ–ª—ñ–≤), –æ–±—Ä–æ–±–ª—è—î–º–æ —á–∞—Å—Ç–∏–Ω–∞–º–∏")
                return self._correct_text_batch_chunked(texts_to_process, language, text_indices, cached_results)
            
            # –û–±'—î–¥–Ω—É—î–º–æ –≤—Å—ñ —Ä–µ—á–µ–Ω–Ω—è –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç –¥–ª—è –∫–æ—Ä–µ–∫—Ü—ñ—ó
            combined_text = " ".join(all_sentences)
            
            # –í–∏–∫–æ–Ω—É—î–º–æ –∫–æ—Ä–µ–∫—Ü—ñ—é (–±–µ–∑–ø–µ—á–Ω–∏–π —Å–ø–æ—Å—ñ–± –±–µ–∑ utils.correct)
            matches = self.language_tool.check(combined_text)
            corrected_text = combined_text
            for match in reversed(matches):  # –û–±—Ä–æ–±–ª—è—î–º–æ –∑ –∫—ñ–Ω—Ü—è —â–æ–± –Ω–µ –∑–º—ñ–Ω—é–≤–∞—Ç–∏ —ñ–Ω–¥–µ–∫—Å–∏
                if match.replacements:
                    corrected_text = corrected_text[:match.offset] + match.replacements[0] + corrected_text[match.offset + match.errorLength:]
            
            # –ö–µ—à—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–∏–π hash)
            import hashlib
            combined_hash = hashlib.md5(combined_text.encode("utf-8")).hexdigest()
            self._language_tool_cache[combined_hash] = corrected_text
            
            # –†–æ–∑–±–∏–≤–∞—î–º–æ –Ω–∞–∑–∞–¥ –Ω–∞ —Ä–µ—á–µ–Ω–Ω—è
            corrected_sentences = self._split_into_sentences(corrected_text)
            
            # –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–µ–∫—Å—Ç—ñ–≤
            corrected_texts = [""] * len(texts)
            
            # –°–ø–æ—á–∞—Ç–∫—É –¥–æ–¥–∞—î–º–æ –∫–µ—à–æ–≤–∞–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
            for i, result in cached_results.items():
                corrected_texts[i] = result
            
            # –ü–æ—Ç—ñ–º –æ–±—Ä–æ–±–ª—è—î–º–æ –Ω–æ–≤—ñ —Ç–µ–∫—Å—Ç–∏
            for text_idx, text in enumerate(texts_to_process):
                original_idx = text_indices[text_idx]
                
                # –ó–Ω–∞—Ö–æ–¥–∏–º–æ —Ä–µ—á–µ–Ω–Ω—è –¥–ª—è —Ü—å–æ–≥–æ —Ç–µ–∫—Å—Ç—É
                text_sentences = []
                for mapping_text_idx, sentence_idx in sentence_mapping:
                    if mapping_text_idx == text_idx:
                        if sentence_idx < len(corrected_sentences):
                            text_sentences.append(corrected_sentences[sentence_idx])
                        else:
                            # Fallback –Ω–∞ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ —Ä–µ—á–µ–Ω–Ω—è
                            original_sentences = self._split_into_sentences(text)
                            if len(text_sentences) < len(original_sentences):
                                text_sentences.append(original_sentences[len(text_sentences)])
                
                # –û–±'—î–¥–Ω—É—î–º–æ —Ä–µ—á–µ–Ω–Ω—è –Ω–∞–∑–∞–¥ –≤ —Ç–µ–∫—Å—Ç
                corrected_texts[original_idx] = " ".join(text_sentences) if text_sentences else text
                
                # –ö–µ—à—É—î–º–æ —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–¥–µ—Ç–µ—Ä–º—ñ–Ω–æ–≤–∞–Ω–∏–π hash)
                import hashlib
                text_hash = hashlib.md5(text.encode("utf-8")).hexdigest()
                self._language_tool_cache[text_hash] = corrected_texts[original_idx]
            
            logger.debug(f"–ü–∞–∫–µ—Ç–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è: {len(all_sentences)} —Ä–µ—á–µ–Ω—å –æ–±—Ä–æ–±–ª–µ–Ω–æ, {len(cached_results)} –∑ –∫–µ—à—É")
            return corrected_texts
            
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ—ó –∫–æ—Ä–µ–∫—Ü—ñ—ó –ø–æ —Ä–µ—á–µ–Ω–Ω—è—Ö: {e}")
            # Fallback –Ω–∞ —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω—É –∫–æ—Ä–µ–∫—Ü—ñ—é
            return [self._correct_text(text, language) for text in texts]
    
    def _correct_text_batch_chunked(self, texts: List[str], language: str, text_indices: List[int], cached_results: dict) -> List[str]:
        """–û–±—Ä–æ–±–∫–∞ –≤–µ–ª–∏–∫–∏—Ö —Ç–µ–∫—Å—Ç—ñ–≤ —á–∞—Å—Ç–∏–Ω–∞–º–∏"""
        corrected_texts = [""] * (len(texts) + len(cached_results))
        
        # –î–æ–¥–∞—î–º–æ –∫–µ—à–æ–≤–∞–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        for i, result in cached_results.items():
            corrected_texts[i] = result
        
        # –û–±—Ä–æ–±–ª—è—î–º–æ —Ç–µ–∫—Å—Ç–∏ —á–∞—Å—Ç–∏–Ω–∞–º–∏
        chunk_size = 3  # –û–±—Ä–æ–±–ª—è—î–º–æ –ø–æ 3 —Ç–µ–∫—Å—Ç–∏ –∑–∞ —Ä–∞–∑
        for i in range(0, len(texts), chunk_size):
            chunk_texts = texts[i:i+chunk_size]
            chunk_indices = text_indices[i:i+chunk_size]
            
            try:
                chunk_results = self._correct_text_batch(chunk_texts, language)
                for j, result in enumerate(chunk_results):
                    corrected_texts[chunk_indices[j]] = result
            except Exception as e:
                logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —á–∞—Å—Ç–∏–Ω–∏ —Ç–µ–∫—Å—Ç—É: {e}")
                # Fallback –Ω–∞ —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω—É –∫–æ—Ä–µ–∫—Ü—ñ—é
                for j, text in enumerate(chunk_texts):
                    corrected_texts[chunk_indices[j]] = self._correct_text(text, language)
        
        return corrected_texts
    
    def _split_into_sentences(self, text: str) -> List[str]:
        """–†–æ–∑–±–∏–≤–∞—î —Ç–µ–∫—Å—Ç –Ω–∞ —Ä–µ—á–µ–Ω–Ω—è (–ø—Ä–æ—Å—Ç–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏)"""
        if not text.strip():
            return []
        
        # –ü—Ä–æ—Å—Ç–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–æ–∑–±–∏—Ç—Ç—è –Ω–∞ —Ä–µ—á–µ–Ω–Ω—è
        import re
        
        # –î–æ–¥–∞—î–º–æ –ø—Ä–æ–±—ñ–ª–∏ –ø–µ—Ä–µ–¥ –∑–Ω–∞–∫–∞–º–∏ –ø—É–Ω–∫—Ç—É–∞—Ü—ñ—ó
        text = re.sub(r'([.!?])([–ê-–Ø–Ñ–Ü–á“ê])', r'\1 \2', text)
        
        # –†–æ–∑–±–∏–≤–∞—î–º–æ –ø–æ –∑–Ω–∞–∫–∞—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è —Ä–µ—á–µ–Ω—å
        sentences = re.split(r'[.!?]+', text)
        
        # –û—á–∏—â–∞—î–º–æ —Ç–∞ —Ñ—ñ–ª—å—Ç—Ä—É—î–º–æ
        cleaned_sentences = []
        for sentence in sentences:
            sentence = sentence.strip()
            if sentence and len(sentence) > 2:  # –Ü–≥–Ω–æ—Ä—É—î–º–æ –¥—É–∂–µ –∫–æ—Ä–æ—Ç–∫—ñ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∏
                cleaned_sentences.append(sentence)
        
        return cleaned_sentences
    
    def _validate_audio_file(self, audio_path: str) -> None:
        """–ü–µ—Ä–µ–≤—ñ—Ä—è—î —Ä–æ–∑–º—ñ—Ä —Ñ–∞–π–ª—É —Ç–∞ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∞—É–¥—ñ–æ"""
        try:
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ä–æ–∑–º—ñ—Ä —Ñ–∞–π–ª—É
            file_size_mb = os.path.getsize(audio_path) / (1024 * 1024)
            if file_size_mb > MAX_FILE_SIZE_MB:
                raise ValueError(f"–§–∞–π–ª –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏–π: {file_size_mb:.1f}MB > {MAX_FILE_SIZE_MB}MB")
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å –∞—É–¥—ñ–æ (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∫–µ—à —è–∫—â–æ –º–æ–∂–ª–∏–≤–æ)
            try:
                # –°–ø–æ—á–∞—Ç–∫—É —Å–ø—Ä–æ–±—É—î–º–æ –æ—Ç—Ä–∏–º–∞—Ç–∏ –∑ –∫–µ—à—É
                audio, sr = self._load_audio_cached(audio_path)
                # –Ø–∫—â–æ –≤ –∫–µ—à—ñ –±—É–ª–æ 16kHz, –ø–µ—Ä–µ–∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∑ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ—é —á–∞—Å—Ç–æ—Ç–æ—é
                if sr == 16000:
                    audio, sr = librosa.load(audio_path, sr=None, mono=True, dtype=np.float32)
            except:
                # Fallback: –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –Ω–∞–ø—Ä—è–º—É
                audio, sr = librosa.load(audio_path, sr=None, mono=True, dtype=np.float32)
            
            duration_minutes = len(audio) / sr / 60
            if duration_minutes > MAX_AUDIO_DURATION_MINUTES:
                raise ValueError(f"–ê—É–¥—ñ–æ –∑–∞–Ω–∞–¥—Ç–æ –¥–æ–≤–≥–µ: {duration_minutes:.1f}—Ö–≤ > {MAX_AUDIO_DURATION_MINUTES}—Ö–≤")
            
            logger.info(f"‚úÖ –§–∞–π–ª –≤–∞–ª—ñ–¥–Ω–∏–π: {file_size_mb:.1f}MB, {duration_minutes:.1f}—Ö–≤")
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó —Ñ–∞–π–ª—É: {e}")
            raise

    def transcribe_simple(self, audio_path: str, language: str = "uk", model_size: str = "auto", use_parallel: bool = False, force_no_chunks: bool = True) -> Dict[str, Any]:
        """–®–≤–∏–¥–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –∑ –æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–∏–º –ø–∞—Ä–∞–ª–µ–ª—å–Ω–∏–º –æ–±—Ä–æ–±–ª–µ–Ω–Ω—è–º"""
        if not self.models_loaded:
            raise RuntimeError("–ú–æ–¥–µ–ª—ñ –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ñ–∞–π–ª –ø–µ—Ä–µ–¥ –æ–±—Ä–æ–±–∫–æ—é
        self._validate_audio_file(audio_path)
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ç–∏—Å–∫ –Ω–∞ –ø–∞–º'—è—Ç—å
        if MEMORY_MONITOR_AVAILABLE and memory_monitor.check_memory_pressure():
            logger.warning("‚ö†Ô∏è –í–∏—Å–æ–∫–∏–π —Ç–∏—Å–∫ –Ω–∞ –ø–∞–º'—è—Ç—å, –ø—Ä–∏–º—É—Å–æ–≤–µ –æ—á–∏—â–µ–Ω–Ω—è")
            memory_monitor.force_garbage_collection()
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–º—ñ–Ω–∏—Ç–∏ –º–æ–¥–µ–ª—å
        if model_size != "auto" and model_size != self.whisper_model.model_size:
            logger.info(f"üîÑ –ó–º—ñ–Ω–∞ –º–æ–¥–µ–ª—ñ –∑ {self.whisper_model.model_size} –Ω–∞ {model_size}")
            if not self.load_models(model_size):
                logger.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å {model_size}, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø–æ—Ç–æ—á–Ω–∞")
        
        start_time = time.time()
        
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É –ø–∞–º'—è—Ç—ñ
        if MEMORY_MONITOR_AVAILABLE:
            with memory_monitor.memory_context("—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è"):
                try:
                    logger.info(f"–ü–æ—á–∞—Ç–æ–∫ —à–≤–∏–¥–∫–æ—ó —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∑ faster-whisper (–º–æ–¥–µ–ª—å: {self.whisper_model.model_size})...")
                    
                    # –ó–∞–≤–∂–¥–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—É –æ–±—Ä–æ–±–∫—É (—á–∞–Ω–∫–∏ –≤–∏–º–∫–Ω–µ–Ω–æ)
                    logger.info("üö´ –ß–∞–Ω–∫–∏ –≤–∏–º–∫–Ω–µ–Ω–æ - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–∞ –æ–±—Ä–æ–±–∫–∞")
                    transcription_result = self.whisper_model.transcribe(audio_path, language)
                    
                    # –û–±—Ä–æ–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –∑ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–æ—é –∫–æ—Ä–µ–∫—Ü—ñ—î—é
                    processed_result = self._process_simple_results(transcription_result, language)
                    
                    elapsed_time = time.time() - start_time
                    logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø—ñ—à–Ω–æ –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")
                    
                    # –û—á–∏—â—É—î–º–æ –∫–µ—à—ñ –¥–ª—è –µ–∫–æ–Ω–æ–º—ñ—ó –ø–∞–º'—è—Ç—ñ
                    self.clear_all_caches()
                    
                    # –ü—Ä–∏–º—É—Å–æ–≤–µ –æ—á–∏—â–µ–Ω–Ω—è –ø–∞–º'—è—Ç—ñ
                    import gc
                    for _ in range(3):
                        gc.collect()
                    
                    # –û—á–∏—â–µ–Ω–Ω—è –∫–µ—à—É Python
                    import sys
                    if hasattr(sys, '_clear_type_cache'):
                        sys._clear_type_cache()
                    
                    logger.info("üßπ –ü—Ä–∏–º—É—Å–æ–≤–µ –æ—á–∏—â–µ–Ω–Ω—è –ø–∞–º'—è—Ç—ñ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
                    
                    return processed_result
                    
                except Exception as e:
                    logger.error(f"–ü–æ–º–∏–ª–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó: {e}")
                    raise
        else:
            # Fallback –±–µ–∑ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É –ø–∞–º'—è—Ç—ñ
            try:
                logger.info(f"–ü–æ—á–∞—Ç–æ–∫ —à–≤–∏–¥–∫–æ—ó —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∑ faster-whisper (–º–æ–¥–µ–ª—å: {self.whisper_model.model_size})...")
                
                # –ó–∞–≤–∂–¥–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—É –æ–±—Ä–æ–±–∫—É (—á–∞–Ω–∫–∏ –≤–∏–º–∫–Ω–µ–Ω–æ)
                logger.info("üö´ –ß–∞–Ω–∫–∏ –≤–∏–º–∫–Ω–µ–Ω–æ - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–∞ –æ–±—Ä–æ–±–∫–∞")
                transcription_result = self.whisper_model.transcribe(audio_path, language)
                
                # –û–±—Ä–æ–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –∑ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–æ—é –∫–æ—Ä–µ–∫—Ü—ñ—î—é
                processed_result = self._process_simple_results(transcription_result, language)
                
                elapsed_time = time.time() - start_time
                logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø—ñ—à–Ω–æ –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")
                
                # –û—á–∏—â—É—î–º–æ –∫–µ—à—ñ –¥–ª—è –µ–∫–æ–Ω–æ–º—ñ—ó –ø–∞–º'—è—Ç—ñ
                self.clear_all_caches()
                
                # –ü—Ä–∏–º—É—Å–æ–≤–µ –æ—á–∏—â–µ–Ω–Ω—è –ø–∞–º'—è—Ç—ñ
                import gc
                for _ in range(3):
                    gc.collect()
                
                # –û—á–∏—â–µ–Ω–Ω—è –∫–µ—à—É Python
                import sys
                if hasattr(sys, '_clear_type_cache'):
                    sys._clear_type_cache()
                
                logger.info("üßπ –ü—Ä–∏–º—É—Å–æ–≤–µ –æ—á–∏—â–µ–Ω–Ω—è –ø–∞–º'—è—Ç—ñ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
                
                return processed_result
                
            except Exception as e:
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó: {e}")
                raise
    
    def transcribe_with_diarization(self, audio_path: str, language: str = "uk", model_size: str = "auto", use_parallel: bool = False, force_no_chunks: bool = True) -> Dict[str, Any]:
        """–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –∑ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—î—é (–û–ø–µ—Ä–∞—Ç–æ—Ä/–ö–ª—ñ—î–Ω—Ç) –∑ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—é –æ–±—Ä–æ–±–∫–æ—é"""
        if not self.models_loaded:
            raise RuntimeError("–ú–æ–¥–µ–ª—ñ –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –ø–æ—Ç—Ä—ñ–±–Ω–æ –∑–º—ñ–Ω–∏—Ç–∏ –º–æ–¥–µ–ª—å
        if model_size != "auto" and model_size != self.whisper_model.model_size:
            logger.info(f"üîÑ –ó–º—ñ–Ω–∞ –º–æ–¥–µ–ª—ñ –∑ {self.whisper_model.model_size} –Ω–∞ {model_size}")
            if not self.load_models(model_size):
                logger.warning(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å {model_size}, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø–æ—Ç–æ—á–Ω–∞")
        
        # Lazy loading –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó - —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –ø—Ä–∏ –ø–æ—Ç—Ä–µ–±—ñ
        if not ENABLE_DIARIZATION:
            logger.warning("‚ö†Ô∏è –î—ñ–∞—Ä–∏–∑–∞—Ü—ñ—è –≤—ñ–¥–∫–ª—é—á–µ–Ω–∞ –≤ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó")
            raise RuntimeError("–î—ñ–∞—Ä–∏–∑–∞—Ü—ñ—è –≤—ñ–¥–∫–ª—é—á–µ–Ω–∞ –≤ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó")
        
        if self.diarization_service is None:
            logger.info("üîß –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó (lazy loading)...")
            self.diarization_service = SimpleDiarizationService(self)
        
        start_time = time.time()
        try:
            logger.info("–ü–æ—á–∞—Ç–æ–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∑ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—î—é...")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —Ñ–∞–π–ª —Ç–∞ –æ—Ç—Ä–∏–º—É—î–º–æ –∞—É–¥—ñ–æ –º–∞—Å–∏–≤ –Ω–∞–ø—Ä—è–º—É
            audio, sr = self.whisper_model._convert_to_optimal_format(audio_path)
            logger.info(f"üîÑ –ö–æ–Ω–≤–µ—Ä—Ç–æ–≤–∞–Ω–æ –∞—É–¥—ñ–æ: {len(audio)} –∑—Ä–∞–∑–∫—ñ–≤, {sr}Hz")
            
            # –î—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∞—É–¥—ñ–æ
            audio_duration = len(audio) / sr
            logger.info(f"üìä –ê—É–¥—ñ–æ –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å={audio_duration:.2f}—Å, —á–∞—Å—Ç–æ—Ç–∞={sr}Hz, –∑—Ä–∞–∑–∫—ñ–≤={len(audio)}")
            logger.info(f"üìä –ü–µ—Ä—à—ñ 0.5—Å –∞—É–¥—ñ–æ: min={audio[:int(0.5*sr)].min():.4f}, max={audio[:int(0.5*sr)].max():.4f}, rms={np.sqrt(np.mean(audio[:int(0.5*sr)]**2)):.4f}")
            
            # –†–æ–±–∏–º–æ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—é –∑ –∞—É–¥—ñ–æ –º–∞—Å–∏–≤–æ–º
            speaker_segments = self.diarization_service.process_audio_array(audio, sr)
            
            if not speaker_segments:
                logger.warning("–î—ñ–∞—Ä–∏–∑–∞—Ü—ñ—è –Ω–µ –∑–Ω–∞–π—à–ª–∞ —Å–µ–≥–º–µ–Ω—Ç–∏, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø—Ä–æ—Å—Ç—É —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—é")
                return self.transcribe_simple(audio_path, language, use_parallel)
            
            if use_parallel and len(speaker_segments) > 1:
                # –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –∑ ThreadPoolExecutor
                logger.info(f"–ü–∞—Ä–∞–ª–µ–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ {len(speaker_segments)} —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó...")
                processed_segments = self._process_diarization_segments_parallel(
                    audio, sr, speaker_segments, language
                )
            else:
                # –ü–æ—Å–ª—ñ–¥–æ–≤–Ω–∞ –æ–±—Ä–æ–±–∫–∞ (fallback)
                processed_segments = self._process_diarization_segments_sequential(
                    audio, sr, speaker_segments, language
                )
            
            # –ü—ñ–¥—Ä–∞—Ö–æ–≤—É—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–∏–∫—Ç–æ—Ä–∞—Ö
            speakers_stats = {}
            full_text = ""
            
            # –°–æ—Ä—Ç—É—î–º–æ —Å–µ–≥–º–µ–Ω—Ç–∏ –∑–∞ —á–∞—Å–æ–º –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ—Ä—è–¥–∫—É
            processed_segments.sort(key=lambda x: x["start"])
            
            for segment in processed_segments:
                speaker = segment["speaker"]
                if speaker not in speakers_stats:
                    speakers_stats[speaker] = {
                        "speaker": speaker,
                        "segments_count": 0,
                        "total_duration": 0,
                        "first_segment": segment["start"],
                        "last_segment": segment["end"]
                    }
                
                speakers_stats[speaker]["segments_count"] += 1
                speakers_stats[speaker]["total_duration"] += segment["duration"]
                speakers_stats[speaker]["last_segment"] = max(speakers_stats[speaker]["last_segment"], segment["end"])
                
                # –î–æ–¥–∞—î–º–æ —á–∞—Å –¥–æ —Ç–µ–∫—Å—Ç—É –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è
                time_info = f"[{segment['start']:.1f}s-{segment['end']:.1f}s]"
                full_text += f"{time_info} [{speaker}]: {segment['text']}\n"
            
            result = {
                "text": full_text.strip(),
                "segments": processed_segments,
                "speakers": list(speakers_stats.values()),
                "duration": max([s["end"] for s in processed_segments]) if processed_segments else 0,
                "language": language,
                "diarization_type": "simple_alternating_parallel" if use_parallel else "simple_alternating"
            }
            
            elapsed_time = time.time() - start_time
            logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—è –∑ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—î—é –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(processed_segments)} —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")
            
            # –û—á–∏—â—É—î–º–æ –∫–µ—à—ñ –¥–ª—è –µ–∫–æ–Ω–æ–º—ñ—ó –ø–∞–º'—è—Ç—ñ
            self.clear_all_caches()
            
            return result
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∑ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—î—é: {e}")
            raise
    
    def _process_diarization_segments_parallel(self, audio: np.ndarray, sr: int, 
                                             speaker_segments: List[Dict[str, Any]], 
                                             language: str) -> List[Dict[str, Any]]:
        """–ü–∞—Ä–∞–ª–µ–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó –∑ threads (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ –¥–ª—è CPU)"""
        try:
            from concurrent.futures import ThreadPoolExecutor
            import os
            
            # –î–∏–Ω–∞–º—ñ—á–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –ø–æ—Ç–æ–∫—ñ–≤ (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞ 14GB RAM + 8 CPU)
            cpu_count = os.cpu_count()
            max_workers = min(DIARIZATION_MAX_WORKERS, len(speaker_segments), cpu_count - 1)  # –ó–∞–ª–∏—à–∞—î–º–æ 1 CPU –¥–ª—è —Å–∏—Å—Ç–µ–º–∏
            logger.info(f"üöÄ –°–µ—Ä–≤–µ—Ä {cpu_count} CPU + 14GB RAM - –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è {max_workers} –ø–æ—Ç–æ–∫—ñ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—ó –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó (threads)")
            
            # –Ø–∫—â–æ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –º–∞–ª–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—É –æ–±—Ä–æ–±–∫—É
            if len(speaker_segments) <= 2 or max_workers <= 1:
                logger.info("–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–∞ –æ–±—Ä–æ–±–∫–∞ (–º–∞–ª–æ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤)")
                return self._process_diarization_segments_sequential(audio, sr, speaker_segments, language)
            
            # –ü–∞—Ä–∞–ª–µ–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –∑ ThreadPoolExecutor (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –æ–¥–Ω—É –º–æ–¥–µ–ª—å)
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # –°—Ç–≤–æ—Ä—é—î–º–æ –∑–∞–≤–¥–∞–Ω–Ω—è –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç—É
                futures = [
                    executor.submit(
                        self._process_single_diarization_segment_threaded,
                        audio, sr, segment, language
                    )
                    for segment in speaker_segments
                ]
                
                # –ß–µ–∫–∞—î–º–æ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –≤—Å—ñ—Ö –∑–∞–≤–¥–∞–Ω—å
                processed_segments = []
                for i, future in enumerate(futures):
                    try:
                        result = future.result(timeout=300)  # 5 —Ö–≤–∏–ª–∏–Ω timeout
                        if result:
                            processed_segments.append(result)
                        
                        # –õ–æ–≥—É—î–º–æ –ø—Ä–æ–≥—Ä–µ—Å –∫–æ–∂–Ω—ñ 3 —Å–µ–≥–º–µ–Ω—Ç–∏
                        if (i + 1) % 3 == 0:
                            logger.info(f"–ü–∞—Ä–∞–ª–µ–ª—å–Ω–æ –æ–±—Ä–æ–±–ª–µ–Ω–æ {i + 1}/{len(speaker_segments)} —Å–µ–≥–º–µ–Ω—Ç—ñ–≤")
                            
                    except Exception as e:
                        logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —Å–µ–≥–º–µ–Ω—Ç—É {speaker_segments[i].get('speaker', 'unknown')}: {e}")
                        continue
            
            logger.info(f"–ü–∞—Ä–∞–ª–µ–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(processed_segments)}/{len(speaker_segments)} —Å–µ–≥–º–µ–Ω—Ç—ñ–≤")
            return processed_segments
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó: {e}")
            # Fallback –¥–æ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—ó –æ–±—Ä–æ–±–∫–∏
            return self._process_diarization_segments_sequential(audio, sr, speaker_segments, language)
    
    def _process_single_diarization_segment_threaded(self, audio: np.ndarray, sr: int,
                                                    speaker_info: Dict[str, Any], 
                                                    language: str) -> Optional[Dict[str, Any]]:
        """Threaded –æ–±—Ä–æ–±–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç—É –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î —ñ—Å–Ω—É—é—á—É –º–æ–¥–µ–ª—å)"""
        try:
            start_time = speaker_info["start"]
            end_time = speaker_info["end"]
            speaker = speaker_info["speaker"]
            
            # –í–∏—Ç—è–≥—É—î–º–æ —Å–µ–≥–º–µ–Ω—Ç –∞—É–¥—ñ–æ –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ–≥–æ –º–∞—Å–∏–≤—É
            start_sample = int(start_time * sr)
            end_sample = int(end_time * sr)
            segment_audio = audio[start_sample:end_sample]
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ segment_audio –≤ BytesIO –¥–ª—è –±–µ–∑–ø–µ—á–Ω–æ—ó –ø–µ—Ä–µ–¥–∞—á—ñ
            from io import BytesIO
            import soundfile as sf
            
            buf = BytesIO()
            sf.write(buf, segment_audio, sr, format="WAV", subtype='PCM_16')
            buf.seek(0)
            
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —ñ—Å–Ω—É—é—á—É –º–æ–¥–µ–ª—å (thread-safe –¥–ª—è CPU)
            segments, info = self.whisper_model.model.transcribe(
                buf,  # –ü–µ—Ä–µ–¥–∞—î–º–æ BytesIO –∑–∞–º—ñ—Å—Ç—å –º–∞—Å–∏–≤—É
                language=language,
                beam_size=self.beam_size,
                word_timestamps=False,  # –®–≤–∏–¥—à–µ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç—ñ–≤
                vad_filter=False,  # –®–≤–∏–¥—à–µ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç—ñ–≤
                temperature=0.0,
                best_of=1,
            )
            
            # –û–±—Ä–æ–±–ª—è—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            segment_text = ""
            for segment in segments:
                segment_text += segment.text + " "
            
            if segment_text.strip():
                # –û—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è
                if language == "uk":
                    segment_text = self._correct_text(segment_text.strip(), language)
                
                return {
                    "start": start_time,
                    "end": end_time,
                    "text": segment_text.strip(),
                    "speaker": speaker,
                    "duration": end_time - start_time
                }
            
            return None
            
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ threaded –æ–±—Ä–æ–±–∫–∏ —Å–µ–≥–º–µ–Ω—Ç—É {speaker}: {e}")
            return None
    
    @staticmethod
    def _process_single_diarization_segment_worker_optimized(audio: np.ndarray, sr: int,
                                                           speaker_info: Dict[str, Any], 
                                                           language: str) -> Optional[Dict[str, Any]]:
        """–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–π worker –¥–ª—è multiprocessing (—Å—Ç–∞—Ç–∏—á–Ω–∏–π –º–µ—Ç–æ–¥)"""
        try:
            # –Ü–º–ø–æ—Ä—Ç—É—î–º–æ —Ç—É—Ç, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –ø—Ä–æ–±–ª–µ–º –∑ multiprocessing
            from faster_whisper import WhisperModel
            import torch
            
            start_time = speaker_info["start"]
            end_time = speaker_info["end"]
            speaker = speaker_info["speaker"]
            
            # –í–∏—Ç—è–≥—É—î–º–æ —Å–µ–≥–º–µ–Ω—Ç –∞—É–¥—ñ–æ –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ–≥–æ –º–∞—Å–∏–≤—É
            start_sample = int(start_time * sr)
            end_sample = int(end_time * sr)
            segment_audio = audio[start_sample:end_sample]
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø—Ä–∏—Å—Ç—Ä—ñ–π —Ç–∞ compute_type (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞ 14GB RAM + 8 CPU)
            device = "cuda" if torch.cuda.is_available() else "cpu"
            if device == "cpu":
                try:
                    import psutil
                    memory_gb = psutil.virtual_memory().total / (1024**3)
                    cpu_count = psutil.cpu_count()
                    
                    if memory_gb >= 14 and cpu_count >= 8:
                        compute_type = "int8_float16"  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è –≤–∞—à–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
                    elif memory_gb >= 8:
                        compute_type = "int8_float16"  # –®–≤–∏–¥—à–µ –Ω—ñ–∂ int8
                    else:
                        compute_type = "int8"  # –ï–∫–æ–Ω–æ–º–Ω—ñ—à–µ –ø–æ –ø–∞–º'—è—Ç—ñ
                except:
                    compute_type = "int8"
            else:
                compute_type = "float16"
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å –≤ worker –ø—Ä–æ—Ü–µ—Å—ñ (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ –¥–ª—è 8 CPU)
            model = WhisperModel("base", device=device, compute_type=compute_type, cpu_threads=4)
            
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É—î–º–æ —Å–µ–≥–º–µ–Ω—Ç –∑ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            segments, info = model.transcribe(
                segment_audio,
                language=language,
                beam_size=1,  # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
                word_timestamps=False,  # –®–≤–∏–¥—à–µ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç—ñ–≤
                vad_filter=False,  # –®–≤–∏–¥—à–µ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç—ñ–≤
                temperature=0.0,
                best_of=1,
            )
            
            # –û–±—Ä–æ–±–ª—è—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            segment_text = ""
            for segment in segments:
                segment_text += segment.text + " "
            
            if segment_text.strip():
                return {
                    "start": start_time,
                    "end": end_time,
                    "text": segment_text.strip(),
                    "speaker": speaker,
                    "duration": end_time - start_time
                }
            
            return None
            
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ worker –æ–±—Ä–æ–±–∫–∏ —Å–µ–≥–º–µ–Ω—Ç—É {speaker}: {e}")
            return None
    
    def _process_single_diarization_segment_optimized(self, audio: np.ndarray, sr: int,
                                                     speaker_info: Dict[str, Any], 
                                                     language: str) -> Optional[Dict[str, Any]]:
        """–û–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç—É –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î —ñ—Å–Ω—É—é—á—É –º–æ–¥–µ–ª—å)"""
        try:
            start_time = speaker_info["start"]
            end_time = speaker_info["end"]
            speaker = speaker_info["speaker"]
            
            # –í–∏—Ç—è–≥—É—î–º–æ —Å–µ–≥–º–µ–Ω—Ç –∞—É–¥—ñ–æ –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ–≥–æ –º–∞—Å–∏–≤—É
            start_sample = int(start_time * sr)
            end_sample = int(end_time * sr)
            segment_audio = audio[start_sample:end_sample]
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ segment_audio –≤ BytesIO –¥–ª—è –±–µ–∑–ø–µ—á–Ω–æ—ó –ø–µ—Ä–µ–¥–∞—á—ñ
            from io import BytesIO
            import soundfile as sf
            
            buf = BytesIO()
            sf.write(buf, segment_audio, sr, format="WAV", subtype='PCM_16')
            buf.seek(0)
            
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —ñ—Å–Ω—É—é—á—É –º–æ–¥–µ–ª—å –∑–∞–º—ñ—Å—Ç—å —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–æ–≤–æ—ó
            segments, info = self.whisper_model.model.transcribe(
                buf,  # –ü–µ—Ä–µ–¥–∞—î–º–æ BytesIO –∑–∞–º—ñ—Å—Ç—å –º–∞—Å–∏–≤—É
                language=language,
                beam_size=self.beam_size,
                word_timestamps=False,  # –®–≤–∏–¥—à–µ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç—ñ–≤
                vad_filter=False,  # –®–≤–∏–¥—à–µ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç—ñ–≤
                temperature=0.0,
                best_of=1,
            )
            
            # –û–±—Ä–æ–±–ª—è—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            segment_text = ""
            for segment in segments:
                segment_text += segment.text + " "
            
            if segment_text.strip():
                # –û—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è
                if language == "uk":
                    segment_text = self._correct_text(segment_text.strip(), language)
                
                return {
                    "start": start_time,
                    "end": end_time,
                    "text": segment_text.strip(),
                    "speaker": speaker,
                    "duration": end_time - start_time
                }
            
            return None
            
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —Å–µ–≥–º–µ–Ω—Ç—É {speaker}: {e}")
            return None
    
    def _process_diarization_segments_sequential(self, audio: np.ndarray, sr: int,
                                               speaker_segments: List[Dict[str, Any]], 
                                               language: str) -> List[Dict[str, Any]]:
        """–ü–æ—Å–ª—ñ–¥–æ–≤–Ω–∞ –æ–±—Ä–æ–±–∫–∞ —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó (fallback)"""
        processed_segments = []
        
        for speaker_info in speaker_segments:
            try:
                result = self._process_single_diarization_segment_optimized(audio, sr, speaker_info, language)
                if result:
                    processed_segments.append(result)
            except Exception as e:
                logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —Å–µ–≥–º–µ–Ω—Ç—É {speaker_info.get('speaker', 'unknown')}: {e}")
                continue
        
        return processed_segments
    
    def _process_single_diarization_segment(self, audio: np.ndarray, sr: int,
                                          speaker_info: Dict[str, Any], 
                                          language: str) -> Optional[Dict[str, Any]]:
        """–û–±—Ä–æ–±–∫–∞ –æ–¥–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç—É –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó (fallback –∑ —Ç–∏–º—á–∞—Å–æ–≤–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏)"""
        try:
            start_time = speaker_info["start"]
            end_time = speaker_info["end"]
            speaker = speaker_info["speaker"]
            
            # –í–∏—Ç—è–≥—É—î–º–æ —Å–µ–≥–º–µ–Ω—Ç –∞—É–¥—ñ–æ –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ–≥–æ –º–∞—Å–∏–≤—É
            start_sample = int(start_time * sr)
            end_sample = int(end_time * sr)
            segment_audio = audio[start_sample:end_sample]
            
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤–∏–π —Ñ–∞–π–ª –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç—É (fallback –º–µ—Ç–æ–¥)
            segment_path = f"temp_segment_{start_time:.1f}_{end_time:.1f}.wav"
            sf.write(segment_path, segment_audio, sr, format='WAV', subtype='PCM_16')
            
            try:
                # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±—É—î–º–æ —Å–µ–≥–º–µ–Ω—Ç –∑ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                segments, info = self.whisper_model.model.transcribe(
                    segment_path,
                    language=language,
                    beam_size=self.beam_size,
                    word_timestamps=False,  # –®–≤–∏–¥—à–µ
                    vad_filter=False,  # –®–≤–∏–¥—à–µ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç—ñ–≤
                    temperature=0.0,
                    best_of=1,
                )
                
                # –û–±—Ä–æ–±–ª—è—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                segment_text = ""
                for segment in segments:
                    segment_text += segment.text + " "
                
                if segment_text.strip():
                    # –û—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è
                    if language == "uk":
                        segment_text = self._correct_text(segment_text.strip(), language)
                    
                    return {
                        "start": start_time,
                        "end": end_time,
                        "text": segment_text.strip(),
                        "speaker": speaker,
                        "duration": end_time - start_time
                    }
                
                return None
                
            finally:
                # –í–∏–¥–∞–ª—è—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤–∏–π —Ñ–∞–π–ª
                try:
                    os.unlink(segment_path)
                except:
                    pass
                    
        except Exception as e:
            logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —Å–µ–≥–º–µ–Ω—Ç—É {speaker}: {e}")
            return None
    
    def _process_simple_results(self, transcription_result: Dict[str, Any], language: str) -> Dict[str, Any]:
        """–û–±—Ä–æ–±–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –ø—Ä–æ—Å—Ç–æ—ó —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó –∑ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–æ—é –∫–æ—Ä–µ–∫—Ü—ñ—î—é"""
        try:
            if not transcription_result or not transcription_result.get("text"):
                return {
                    "text": "–¢–µ–∫—Å—Ç –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ - –∞—É–¥—ñ–æ –º–æ–∂–µ –±—É—Ç–∏ –±–µ–∑ –º–æ–≤–ª–µ–Ω–Ω—è –∞–±–æ –∑–∞–Ω–∞–¥—Ç–æ —Ç–∏—Ö–∏–º",
                    "segments": [],
                    "duration": 0,
                    "language": language
                }
            
            # –û—Ç—Ä–∏–º—É—î–º–æ —Ç–µ–∫—Å—Ç
            text = transcription_result.get("text", "").strip()
            
            # –ü–µ—Ä–µ–∫–æ–Ω—É—î–º–æ—Å—è, —â–æ —Ç–µ–∫—Å—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∫–æ–¥—É—î—Ç—å—Å—è –≤ UTF-8
            if isinstance(text, bytes):
                text = text.decode('utf-8', errors='ignore')
            
            # –û—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –º–æ–≤–∏
            if language == "uk":
                text = self._correct_text(text, language)
            
            # –û—Ç—Ä–∏–º—É—î–º–æ —Å–µ–≥–º–µ–Ω—Ç–∏ –∑ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–æ—é –∫–æ—Ä–µ–∫—Ü—ñ—î—é
            segments = []
            segment_texts = []
            
            # –°–ø–æ—á–∞—Ç–∫—É –∑–±–∏—Ä–∞—î–º–æ –≤—Å—ñ —Ç–µ–∫—Å—Ç–∏ –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ—ó –∫–æ—Ä–µ–∫—Ü—ñ—ó
            for segment in transcription_result.get("segments", []):
                segment_text = segment.get("text", "").strip()
                
                # –ü–µ—Ä–µ–∫–æ–Ω—É—î–º–æ—Å—è, —â–æ —Ç–µ–∫—Å—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∫–æ–¥—É—î—Ç—å—Å—è –≤ UTF-8
                if isinstance(segment_text, bytes):
                    segment_text = segment_text.decode('utf-8', errors='ignore')
                
                segment_texts.append(segment_text)
            
            # –ü–∞–∫–µ—Ç–Ω–∞ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ—ñ—á–Ω–∞ –∫–æ—Ä–µ–∫—Ü—ñ—è (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∞)
            if language == "uk" and segment_texts:
                try:
                    corrected_texts = self._correct_text_batch(segment_texts, language)
                    if len(corrected_texts) == len(segment_texts):
                        segment_texts = corrected_texts
                except Exception as e:
                    logger.warning(f"–ü–æ–º–∏–ª–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ—ó –∫–æ—Ä–µ–∫—Ü—ñ—ó: {e}")
            
            # –§–æ—Ä–º—É—î–º–æ —Ñ—ñ–Ω–∞–ª—å–Ω—ñ —Å–µ–≥–º–µ–Ω—Ç–∏
            for i, segment in enumerate(transcription_result.get("segments", [])):
                segment_text = segment_texts[i] if i < len(segment_texts) else segment.get("text", "").strip()
                
                segments.append({
                    "start": segment.get("start", 0),
                    "end": segment.get("end", 0),
                    "text": segment_text
                })
            
            # –û—Ç—Ä–∏–º—É—î–º–æ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å
            duration = transcription_result.get("duration", 0)
            
            return {
                "text": text,
                "segments": segments,
                "duration": duration,
                "language": language
            }
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤: {e}")
            return {
                "text": "–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü—ñ—ó",
                "segments": [],
                "duration": 0,
                "language": language
            }

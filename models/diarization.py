"""
–ü—Ä–æ—Å—Ç–∏–π —Å–µ—Ä–≤—ñ—Å –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó –∑ —á–µ—Ä–≥—É–≤–∞–Ω–Ω—è–º —Ä–æ–ª–µ–π –û–ø–µ—Ä–∞—Ç–æ—Ä/–ö–ª—ñ—î–Ω—Ç
"""

import logging
import numpy as np
from typing import Dict, Any, List, Tuple
import librosa
import webrtcvad

from .config import logger

class SimpleDiarizationService:
    """–ü—Ä–æ—Å—Ç–∏–π —Å–µ—Ä–≤—ñ—Å –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó –∑ —á–µ—Ä–≥—É–≤–∞–Ω–Ω—è–º —Ä–æ–ª–µ–π –û–ø–µ—Ä–∞—Ç–æ—Ä/–ö–ª—ñ—î–Ω—Ç"""
    
    def __init__(self, transcription_service=None):
        self.vad = webrtcvad.Vad(2)  # –ê–≥—Ä–µ—Å–∏–≤–Ω—ñ—Å—Ç—å VAD (0-3, –¥–µ 3 –Ω–∞–π–∞–≥—Ä–µ—Å–∏–≤–Ω—ñ—à–∞)
        self.transcription_service = transcription_service  # –ü–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –æ—Å–Ω–æ–≤–Ω–∏–π —Å–µ—Ä–≤—ñ—Å –¥–ª—è –∫–µ—à—É–≤–∞–Ω–Ω—è
        
    def _detect_speech_segments(self, audio_path: str, min_silence_duration: float = 0.5) -> List[Tuple[float, float]]:
        """–í–∏—è–≤–ª—è—î —Å–µ–≥–º–µ–Ω—Ç–∏ –º–æ–≤–ª–µ–Ω–Ω—è –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é WebRTC VAD"""
        try:
            logger.info(f"–ê–Ω–∞–ª—ñ–∑ –º–æ–≤–ª–µ–Ω–Ω—è –¥–ª—è {audio_path}...")
            
            # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∞—É–¥—ñ–æ —è–∫ 16kHz mono PCM –∑ –∫–µ—à—É–≤–∞–Ω–Ω—è–º
            if self.transcription_service:
                logger.info(f"üîç VAD –∞–Ω–∞–ª—ñ–∑ —Ñ–∞–π–ª—É: {audio_path}")
                audio, sr = self.transcription_service._load_audio_cached(audio_path)
            else:
                logger.info(f"üîç VAD –∞–Ω–∞–ª—ñ–∑ —Ñ–∞–π–ª—É (–±–µ–∑ –∫–µ—à—É): {audio_path}")
                audio, sr = librosa.load(audio_path, sr=16000, mono=True)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ int16 –¥–ª—è WebRTC VAD
            audio_int16 = (audio * 32767).astype(np.int16)
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è VAD
            frame_duration = 30  # –º—Å
            frame_size = int(16000 * frame_duration / 1000)
            
            speech_segments = []
            current_segment_start = None
            in_speech = False
            
            # –û–±—Ä–æ–±–ª—è—î–º–æ –∞—É–¥—ñ–æ –∫–∞–¥—Ä–∞–º–∏
            for i in range(0, len(audio_int16) - frame_size, frame_size):
                frame = audio_int16[i:i + frame_size]
                
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î –º–æ–≤–ª–µ–Ω–Ω—è –≤ –∫–∞–¥—Ä—ñ
                is_speech = self.vad.is_speech(frame.tobytes(), 16000)
                timestamp = i / 16000.0  # —á–∞—Å –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
                
                if is_speech and not in_speech:
                    # –ü–æ—á–∞—Ç–æ–∫ —Å–µ–≥–º–µ–Ω—Ç—É –º–æ–≤–ª–µ–Ω–Ω—è
                    current_segment_start = timestamp
                    in_speech = True
                elif not is_speech and in_speech:
                    # –ö—ñ–Ω–µ—Ü—å —Å–µ–≥–º–µ–Ω—Ç—É –º–æ–≤–ª–µ–Ω–Ω—è
                    segment_duration = timestamp - current_segment_start
                    if segment_duration >= 0.3:  # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç—É
                        speech_segments.append((current_segment_start, timestamp))
                    in_speech = False
            
            # –û–±—Ä–æ–±–ª—è—î–º–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π —Å–µ–≥–º–µ–Ω—Ç
            if in_speech and current_segment_start is not None:
                speech_segments.append((current_segment_start, len(audio_int16) / 16000.0))
            
            logger.info(f"–ó–Ω–∞–π–¥–µ–Ω–æ {len(speech_segments)} —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –º–æ–≤–ª–µ–Ω–Ω—è")
            return speech_segments
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –≤–∏—è–≤–ª–µ–Ω–Ω—è —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –º–æ–≤–ª–µ–Ω–Ω—è: {e}")
            return []
    
    def _merge_close_segments(self, segments: List[Tuple[float, float]], max_gap: float = 1.0) -> List[Tuple[float, float]]:
        """–û–±'—î–¥–Ω—É—î –±–ª–∏–∑—å–∫—ñ —Å–µ–≥–º–µ–Ω—Ç–∏ –º–æ–≤–ª–µ–Ω–Ω—è"""
        if not segments:
            return []
        
        merged = [segments[0]]
        
        for current_start, current_end in segments[1:]:
            last_start, last_end = merged[-1]
            
            # –Ø–∫—â–æ —Å–µ–≥–º–µ–Ω—Ç–∏ –±–ª–∏–∑—å–∫–æ –æ–¥–∏–Ω –¥–æ –æ–¥–Ω–æ–≥–æ, –æ–±'—î–¥–Ω—É—î–º–æ —ó—Ö
            if current_start - last_end <= max_gap:
                merged[-1] = (last_start, current_end)
            else:
                merged.append((current_start, current_end))
        
        return merged
    
    def assign_speakers(self, speech_segments: List[Tuple[float, float]]) -> List[Dict[str, Any]]:
        """–ü—Ä–∏–∑–Ω–∞—á–∞—î —Ä–æ–ª—ñ –û–ø–µ—Ä–∞—Ç–æ—Ä/–ö–ª—ñ—î–Ω—Ç —á–µ—Ä–≥—É—é—á–∏ —ó—Ö"""
        if not speech_segments:
            return []
        
        speaker_assignments = []
        
        for i, (start, end) in enumerate(speech_segments):
            # –ß–µ—Ä–≥—É—î–º–æ —Ä–æ–ª—ñ: –ø–µ—Ä—à–∏–π —Å–µ–≥–º–µ–Ω—Ç - –û–ø–µ—Ä–∞—Ç–æ—Ä, –¥—Ä—É–≥–∏–π - –ö–ª—ñ—î–Ω—Ç, —ñ —Ç.–¥.
            speaker = "–û–ø–µ—Ä–∞—Ç–æ—Ä" if i % 2 == 0 else "–ö–ª—ñ—î–Ω—Ç"
            
            speaker_assignments.append({
                "speaker": speaker,
                "start": start,
                "end": end,
                "duration": end - start
            })
        
        return speaker_assignments
    
    def process_audio(self, audio_path: str) -> List[Dict[str, Any]]:
        """–ü–æ–≤–Ω–∏–π –ø—Ä–æ—Ü–µ—Å –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó –∞—É–¥—ñ–æ"""
        try:
            logger.info("–ü–æ—á–∞—Ç–æ–∫ –ø—Ä–æ—Å—Ç–æ—ó –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó...")
            
            # –í–∏—è–≤–ª—è—î–º–æ —Å–µ–≥–º–µ–Ω—Ç–∏ –º–æ–≤–ª–µ–Ω–Ω—è
            speech_segments = self._detect_speech_segments(audio_path)
            
            if not speech_segments:
                logger.warning("–°–µ–≥–º–µ–Ω—Ç–∏ –º–æ–≤–ª–µ–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
                return []
            
            # –û–±'—î–¥–Ω—É—î–º–æ –±–ª–∏–∑—å–∫—ñ —Å–µ–≥–º–µ–Ω—Ç–∏
            merged_segments = self._merge_close_segments(speech_segments)
            
            # –ü—Ä–∏–∑–Ω–∞—á–∞—î–º–æ —Ä–æ–ª—ñ
            speaker_assignments = self.assign_speakers(merged_segments)
            
            logger.info(f"–î—ñ–∞—Ä–∏–∑–∞—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(speaker_assignments)} —Å–µ–≥–º–µ–Ω—Ç—ñ–≤ –∑ —Ä–æ–ª—è–º–∏")
            return speaker_assignments
            
        except Exception as e:
            logger.error(f"–ü–æ–º–∏–ª–∫–∞ –¥—ñ–∞—Ä–∏–∑–∞—Ü—ñ—ó: {e}")
            return []
